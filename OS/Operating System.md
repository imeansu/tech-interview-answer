## 프로세스와 스레드

프로세스: 프로그램이 메모리에 올라가 CPU의 할당을 받을 수 있는 것

스레드: 프로세스 안의 여러 실행 단위 흐름

프로세스는 자신만의 고유한 공간과 자원을 할당받아 실행됨

스레드는 같은 프로세스 안 다른 스레드와 공간과 자원을 공유함

프로세스는 각각 별도의 주소공간 할당(독립적)

- Code: 코드 자체를 구성하는 메모리 영역
    - 컴파일된 후 기계어 형태
    - 실행코드(Instruction)
    - CPU는 코드 영역에 저장된 명령어를 하나씩 가져가서 처리
    - 읽기 전용
- Data: 전역변수, 정적변수, 배열 등
    - data: 초기화된 데이터
    - bss: 초기화 되지 않은 데이터
    - 전역 변수와 static 변수 등 저장 (메인 함수가 호출되기 전에 할당)
- Heap: 동적 할당 시 사용
    - new(), malloc() 등
    - 언어 마다 Heap에 저장하는 것이 약간 상이
    - 메소드 호출이 끝나도 사라지지 않고 유지 (GC에 의해서 지워지거나 JVM이 종료될 때까지)
    - 모든 Object 타입
    - 8가지 원시 타입을 제외한 모든 정의된 변수들은 참조 변수이다. 참조 변수는 실행될 때마다 많은 데이터들을 스택 메모리 영역에 뒀다 뺐다 하는게 비효율적이므로, 힙역역에 데이터값이 저장되고 스택메모리에는 간단하게 그 주소만 저장됨
- Stack: 지역변수, 매개변수, 리턴 값 (임시 메모리 영역)
    - heap영역에 생성된 Object 타입의 데이터들에 대한 참조를 위한 값이 할당
    - 8가지 원시 타입에 해당하는 지역변수, 매개변수
    - 메소드 종료되면 메모리가 해제
    - Return Address를 Stack에 저장하고 함수에서 필요한 공간을 할당한 뒤 나중에 다시 지운다
    - EBP 레지스터
        - 현재 stack의 최상단을 가리키는 주소가 들어가 있다
        - 함수가 함수를 부르다가 문제가 생기면 어떤 시점에 어떤 함수를 시행시키다가 문제가 생긴지 알기 어려우므로 존재
    - EAX 레지스터
        - Return 값을 가지고 있음

- 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없으며, 접근을 위해서는 IPC 통신이 필요하다
    - ex) 파이프, 파일, 소켓 등

스레드는 

- 스레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택으로 구성
- 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유
- 스택을 스레드마다 독립적으로 할당하는 이유
    - 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 지역 변수 등을 저장하기 위해 사용되는 메모리 공간
    - 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것

프로세스 제어 블록(Process Control Block, PCB)

- 운영체제의 자료구조
- 운영체제는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 PCB를 생성
- 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU를 반환해야 한느데, 이때 작업의 진행 상황을 모두 PCB에 저장. 그리고 다시 CPU를 할당받게 되면 PCB에 저장되어 있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행
- PCB에 저장되는 정보
    - 프로세스 식별자(Process ID, PID) : 프로세스 식별번호
    - 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장
    - 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소
    - CPU 레지스터 (PC, SP 등)
    - CPU 스케쥴링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
    - 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
    - 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
    - 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정번호 등

Context Switching 

- Cache 초기화
- Memory mapping 초기화
- 커널은 항상 실행되어야 한다

스레드는 Stack만 따로 할당 받고 나머지 영역은 서로 공유

하나의 프로세스가 생성될 때, 기본적으로 하나의 스레드 같이 생성

### 멀티프로세스

> 하나의 응용 프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업을 처리하도록 하는 것

장점: 안전성 (메모리 침범 문제를 OS 차원에서 해결 - 메모리 보호로 이냏 커널을 통해(시스템 콜 )통신이 이루어짐)

단점: 각각 독립된 메모리 영역을 갖고 있어, 작업량 많을 수록 오버헤드 발생. Context Switching으로 인한 성능 저하???

### 멀티스레드

> 하나의 응용 프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 처리하는 것

스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해줌

장점

- 독립적인 프로세스에 비해 공유 메모리만큼의 시간, 자원 손실이 감소
- 전역 변수와 정적 변수에 대한 자료 공유 가능
- 프로세스의 Context Switch와 다르게 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다(프로세스 사이에는 공유하는 메로리가 하나도 없기 때문에 cs가 발생하면 캐쉬에 있는 모든 데이터를 리셋하고 다시 캐쉬 정보를 불러와야 함)

단점: 안전성(하나의 스레드가 데이터 공간을 망가뜨리면, 모든 스레드가 작동 불능 상태)

- 스레드를 많이 생성하면, Context Switching이 많이 일어나 성능 저하
    - 리눅스에서는 Thread를 Process와 같이 다룸
        - 가벼운 스레드, 자식 프로세스와 비슷한 방식으로 생성.
        - 부모 프로세스의 PCB 정보를 포함해 모두 갖지만 PCB 내 대부분의 정보가 포인터로 이루어짐
        - 부모 프로세스의 정보를 포인터로만 갖고 있고 몇몇 구조체에서만 자신이 쓰레드임을 알기 위한 다른 정보가 들어 있음
    - 스레드를 많이 생성하면, 모든 스레드를 스케쥴링해야 하므로, CS가 빈번하게 발생
- 멀티스레드의 안전성은 Critical Section 기법을 통해 대비함 (동기화 작업)

    하나의 스레드가 공유 데이터 값을 변경하는 시점에 다른 스레드가 그 값을 읽으려고 할 때 발생하는 문제를 해결하기 위한 동기화 과정

    상호 배제, 진행, 한정된 대기를 충족해야함

### Thread-safe

- 멀티스레드 환경에서 여러 스레드가 동시에 하나의 객체 및 변수(공유 자원)에 접근할 때, 의도한 대로 동작하는 것을 말한다
- 이러한 상황을 "Thread-safe하다"라고 표현
- Thread-safe 하게 구현하기
    - 이를 위해서는 공유 자원에 접근하는 임계영역(critical section)을 동기화 기법으로 제어해줘야 한다. 이를 '상호배제'라고 한다.
    - 동기화 기법으로는 뮤텍스, 세마포어가 존재
- Reentrant
    - 재진입성이라는 의미로, 어떤 함수가 Reentrant하다는 것은 여러 스레드가 동시에 접근해도 언제나 같은 실행 결과를 보장한다는 의미
    - 이를 만족하기 위해서는 해당 서브루틴에서는 공유자원을 사용하지 않으면 된다
        - 예) 정적 변수를 사용하거나 반환하면 안되고 호출 시 제공된 매개변수만으로 동작해야 한다
    - 따라서, Reentrant하다면 Thread-safe하지만 그 역은 성립하지 않는다

## CPU Scheduling

### 스케쥴링

> CPU를 잘 사용하기 위해 프로세스를 잘 배정하기
> 

조건: 오버헤드 ↓ / 사용률 ↑ / 기아 현상 ↓

시스템별 목표

1. Batch System: 가능하면 많은 일을 수행. 시간(time) 보단 처리량(throughout)이 중요
2. Interactive System: 빠른 응답 시간, 적은 대기 시간
3. Real-time System: 기한(deadline) 맞추기

### 스케쥴러

프로세스 스케쥴링을 위한 Queue

- Job Queue: 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device Queue: Device I/O 작업을 대기하고 있는 프로세스의 집합

각각의 Queue에 프로세스들을 넣고 빼주는 스케쥴러에도 크게 세 가지 종류가 존재

1. 장기스케쥴러 (Long-term scheduler or job scheduler)
    - 한정된 메모리, 많은 프로세스가 한꺼번에 메모리에 올라올 경우 → 대용량 메모리에 임시로 저장
    - 이 pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue로 보낼지 결정하는 역할
    - 메모리에 프로그램이 너무 많아도, 너무 적어도 성능은 떨어짐. 참고로 time sharing system에서는 장기 스케쥴러가 없다
    - 프로세스 상태: new → ready(in memory)
2. 단기스케쥴러 (Short-term scheduler or CPU scheduler) 
    - CPU와 메모리 사이의 스케쥴링을 담당
    - Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정 (scheduler dispatch)
    - 프로세스의 상태 : ready -> running -> waiting -> ready
3. 중기스케쥴러 (Medium-term scheduler or Swapper)
    - 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swapping)
    - Unix나 Window에서는 장기 스케쥴러가 거의 사용되지 않는다
    - 프로세스 상태 : ready → suspended
- Process state
    - Suspended(stopped): 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 Swap out 된다
    - Blocked : 다른 I/O  작업을 기다리는 상태이기 대문에 스스로 ready state로 돌아갈 수 있지만, suspended 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다
- 장기 vs 단기
    - 단기스케쥴러는 상당히 빨라야 하고 호출 빈도수가 많다
    - 새로운 작업이 생성되어 들어오는 것은 분 단위로 장기는 호출 빈도수가 단기에 비해 매우 적다 → 장기는 시간이 꽤 걸리더라도 신중하게 프로세스를 선택
    - 장기가 I/O 프로세스나 CPU 중심 프로세스 중 한쪽으로만 편중해서 받아오면 ready queue, device queue 한쪽에 프로세스가 집중되어 단기의 균형도 붕괴된다

### 선점 / 비선점 스케쥴링

- 선점 (preemptive) : OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우
- 비선점 (nonpreemptive) : 프로세스 종료 or I/O 등의 이벤트가 있을 때까지 실행 보장 (처리 시간 예측 어려움)

### 프로세스 상태

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ab549490-5e0a-4805-9be5-4506ef2b25d7/Untitled.png)

- 비선점 스케쥴링: Interrupt, Scheduler Dispatch
- 선점 스케쥴링: I/O or Event Wait
- 프로세스의 상태 전이
    - 승인(Admitted) : 프로세스 생성이 가능하여 승인됨
    - 스케쥴러 디스패치(Scheduler Dispatch) : 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것
    - 인터럽트(Interrupt) : 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것
    - 입출력 또는 이벤트 대기(I/O or Event wait) : 실행 중인 프로세스가 입출력이나 이벤트를 처리해야 하는 경우, 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것
    - 입출력 또는 이벤트 완료(I/O or Event Completion) : 입출력/이벤트가 끝난 프로세스를 준비 상태로 전환하여 스케쥴러에 의해 선택될 수 있도록 만드는 것

### CPU 스케쥴링의 종류

- 비선점 스케쥴링
    1. FCFS (First Come First Served)
        - 큐에 도착한 순서대로 CPU 할당
        - 실행 시간이 짧은 게 뒤로 가면 평균 대기 시간이 길어짐
        
        문제점
        
        - convoy effect : 소요시간이 긴 프로세스가 먼저 도달하여 효율서을 낮추는 현상
    2. SJF (Shortest Job First)
        - 수행시간이 가장 짧다고 판단되는 작업을 먼저 수행
        - FCFS 보다 평균 대기 시간 감소, 짧은 작업에 유리
        
        문제점
        
        - starvation
        - 비현실적, 프로세스의 CPU 점유 시간(Burst time)을 알 수 없다
    3. HRN (Highest Response-ratio Next)
        - 우선순위를 계산하여 점유 불평등을 보완한 방법 (SJF의 단점 보완)
        - 우선순위 = (대기시간 + 실행시간) / 실행시간
- 선점 스케쥴링
    1. Priority Scheduling
        - 정적/동적으로 우선순위를 부여하여 우선순위가 높은 순서대로 처리
        - 우선순위가 낮은 프로세스가 무한정 기다리는 Starvation이 생길 수 있음
        
        문제점
        
        - starvation, 무기한 봉쇄(Indefinite blocking)
        - Aging 방법으로 Starvation 문제 해결 가능
    2. SRT(Shortest Remaining Time)
        - 현재 CPU에서 실행 중인 프로세스의 남은 CPU burst 시간보다 더 짧은 CPU burst 를 가진 프로세스가 도착하면 CPU가 선점
    3. Round Robin
        - FCFS에 의해 프로세스들이 보내지면 각 프로세스는 동일한 시간의 Time Quantum 만큼 CPU를 할당 받음 (Time Quantum or Time Slice : 실행의 최소 단위 시간, 일반적으로 10~100msec 사이의 범위)
        - n 개의 프로세스가 ready queue에 있고 할당 시간이 q인 경우 각 프로세스는 q 단위로 CPU 시간의 1/n 을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
        - 할당 시간(Time Quantum)이 크면 FCFS와 같게 되고, 작으면 문맥 교환 (Context Switching)이 잦아져서 오버헤드 증가
    4. Multilevel-Queue (다단계 큐)
        - 작업들을 여러 종류의 그룹으로 나누어 여러 개의 큐를 이용하는 기법
        - 우선순위가 낮은 큐들이 실행 못하는 걸 방지하고자 각 큐 마다 다른 Time Quantum을 설정해주는 방식 사용
        - 우선순위가 높은 큐는 작은 Time Quantum 할당, 낮은 큐는 큰 Time Quantum 할당
        
        ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/abe3b5ea-f09f-4d43-aa6f-51413bc16b75/Untitled.png)
        
    5. Multilevel-Feedback-Queue (다단계 피드백 큐)
        - 다단계 큐에서 자신의 Time Queantum을 다 채운 프로세스는 밑으로 내려가고 자신의 Time Quantum을 다 채우지 못한 프로세스는 원래 큐 그대로
            - Time Quantum을 다 채운 프로세스는 CPU burst 프로세스로 판단하기 때문
        - 짧은 작업에 유리, 입출력 위주(Interrupt가 잦은) 작업에 우선권을 줌
        - 처리 시간이 짧은 프로세스를 먼저 처리하기 때문에 Turnaround 평균 시간을 줄여줌?
        - 대부분의 상용 운영체제는 여러 개의 큐를 사용하고 각 큐마다 다른 스케쥴링 방식을 사용

### CPU 스케쥴링 척도

1. Response Time: 작업이 처음 실행되기까지 걸린 시간
2. Turnaround Time: 실행 시간과 대기 시간을 모두 합한 시간으로 작업이 완료될 때 까지 걸린 시간

## 데드락(DeadLock)

기아상태(Starvation) : 여러 프로세스가 부족한 자원을 점유하기 위해 경쟁할 때, 특정 프로세스가 영원히? 자원 할당이 되지 않는 경우 (starvation은 ready에서 무한 대기, deadlock은 asleep에서 무한 대기)

→ 우선 순위 변경으로 해결 (수시 변경, 오래 기다린 프로세스의 순위 상승, Queue 사용)

### 데드락(DeadLock)

> 프로세스가 자원을 얻지 못해서 다음 처리를 하지 못하는 상태
'교착 상태'라고도 부름
시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생
> 

DeadLock : 발생할 일이 아예 없는 이벤트나 자원을 기다리는 것

indefinite postponement : 자원을 할당받지 못하고 계속 지연되고 있음. 하지만 할당받을 가능성이 0은 아님

주로 발생하는 경우

- 멀티 프로그래밍 환경에서 한정된 자원을 얻기 위해 서로 경쟁하는 상황 발생
- 한 프로세스가 자원을 요청했을 때, 동시에 그 자원을 사용할 수 없는 상황이 발생할 수 있음. 이때 프로세스는 대기 상태로 들어감
- 대기 상태로 들어간 프로세스들이 실행 상태로 변경될 수 없을 때 '교착 상태' 발생

### 데드락(DeadLock) 발생 조건

4가지 모두 성립해야 데드락 발생 (하나라도 성립하지 않으면 데드락 문제 해결 가능)

1. 상호 배제 (Mutual exclusion)
    
    자원은 한번에 한 프로세스만 사용할 수 있음
    
2. 점유 대기 (Hold and wait)
    
    최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재함
    
3. 비선점 (No preemption)
    
    다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음
    
4. 순환 대기 (Circular wait)
    
    프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함
    

### 데드락(DeadLock) 처리

교착 상태를 예방 & 회피

1. 예방(prevention)
    
    교착 상태 발생 조건 중 하나를 제거하면서 해결한다 (자원 낭비가 매우 심함)
    
    - 상호배제 부정: 여러 프로세스가 공유 자원 사용 (사실 불가능)
    - 점유대기 부정: 프로세스 실행 전 모든 자원을 할당 (내가 사용하지 않는 구간에도 자원을 점유하고 있어서 비효율적)
    - 비선점 부정: 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가지 자원 반납 (가능은 하지만 선점당한 프로세스가 비정상적으로 종료될 수 있음)
    - 순환대기 부정: 자원에 고유번호 할당 후 순서대로 자원 요구 (r1 > r2: O, r2 > r1: X)
2. 회피(avoidance)
    
    교착 상태가 발생하지 않을 안전 상태를 유지하도록
    
    각 프로세스 별로 자원 최대 요구향이 미리 알려져있어야 함 (비현실적)
    
    은행원 알고리즘 (Banker's Algorithm), Dijksta's alorithm, Habermann's algorithm
    
    - 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지 사전에 검사하여 교착 상태 회피
    - 안정 상태면 자원 할당, 아니면 다른 프로세스들이 자원 해지까지 대기
    
> **회피(avoidance)와 탐지(detection)의 차이** 
> 
> **avoidance**
> - considers worst case 
> - 최대 요구량까지 요구하는 최악의 경우에도 교착상태에 걸리지 않는 길이 있는가 
> 
> **detection**
> - considers most favorable case
> - Checks whether current state has deadlocked processes or not
> - Does not consider/respond to the (expected) states in the future
> - 최선의 경우, 현재 요청한 리소스만 할당 받으면 그 프로세스는 더이상 요청하지 않을 거야

교착 상태를 탐지 & 획복

교착 상태가 되도록 허용한 다음 회복시키는 방법?

1. 탐지(Detection)
    - 자원 할당 그래프를 통해 교착 상태를 탐지함
    - 자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생함
    - 현재만 교착 상태가 아니면 됨. best case를 바라봄
2. 회복(Recovery)
    
    교착 상태를 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법
    
    프로세스 종료 방법
    
    - 교착 상태의 프로세스를 모두 중지
    - 교착 상태가 제거될 때까지 하나씩 프로세스 중지
    
    자원 선점 방법
    
    - 교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당 (해당 프로세스 일시정지 시킴)
    - 우선 순위가 낮은 프로세스나 수행 횟수 적은 프로세스 위주로 프로세스 자원 선점


## 세마포어(Semaphore)와 뮤텍스(Mutex)의 차이점

공유된 자원의 데이터는 한번에 하나의 프로세스만 접근할 수 있도록 제한해야 함 → 이를 위해 나온 것이 '세마포어'

### 세마포어

- 멀티프로그래밍 환경에서 공유 자원에 대한 접근을 제한하는 방법
- 기존 Mutual Exclusion 기법의 Busy waiting을 방지하기 위한 기법 (다익스트라가 제안)
- 동시에 접근할 수 있는 '허용 가능한 갯수'를 가지고 있는 Counter.
- 세마포어 Counter의 갯수에 따라
    - 1개: Binary Semaphore
        - Mutex
    - 2개 이상: Counting Semaphore
        - Producer-consumer problem
        - Reader-writer problem
        - Dining philosopher problem
- 세마포어는 소유할 수 없다 : 세마포어를 소유하지 않은 스레드가 세마포어를 해제할 수 있는 문제 발생

### 뮤텍스 (Mutal Exclusion)

- 공유된 자원의 데이터를 여러 프로세스, 스레드가 접근하는 것을 막는 것
- 임계 구역을 가진 스레드들의 Running time이 서로 겹치지 않게 각각 단독으로 실행되게 하는 기술
- 뮤텍스 객체를 두 스레드가 동시에 사용할 수 없다
- Lock에 대한 소유권이 있음. Lock을 가진 사람만 반납할 수 있음.
- 무조건 1개의 열쇠

Race condition

- 여러 프로세스가 같은 데이터를 번갈아 가면서 접근하고 조작할 때, 최종 결과가 접근한 순서에 따라 달라지는 것

임계 구역 (Critical Section)

- 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 부분
- 한 프로세스가 임계 구역을 수행할 때는 다른 프로세스가 접근하지 못하도록 해야 한다
- 임계 구역 문제를 해결하기 위한 3가지 필수 조건
    - 상호 배제
    - 진행(Progress) : 임계 구역에서 실행 중인 프로세스가 없고 별도의 동작이 없는 프로세스들만 임계 구역 진입 후보로서 참여될 수 있다. 어떤 프로세스라도 아무도 CS에 없는데 제한되면 안됨
    - 한정된 대기(Bounded Waiting) : 특정 프로세스는 유한한 시도 내에 CS에 들어갈 수 있어야 한다

세마포어 P(), V() 연산 
- indivisible operation (마치 기계어 명령처럼 중간에 인터럽트를 받으면 안됨) 

- P() : wait(), 임계 구역 들어가기 전에 수행 (프로세스 진입 여부를 자원의 개수(S)를 통해 결정)
- V() : signal(), 임계 구역에서 나올 때 수행 (자원 반납 알림, 대기 중인 프로세스를 깨우는 신호)

## 가상 메모리
[https://wogh8732.tistory.com/395?category=807175](https://wogh8732.tistory.com/395?category=807175)

> 다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야 한다
가상메모리는 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이며, 프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있다
> 

### 가상 메모리가 하는 일

가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것으로 정리할 수 있다. 이로써 작은 메모리를 가지고도 얼마든지 큰 가장 주소 공간을 프로그래머에게 제공할 수 있다

### Concept

- 프로세스의 이미지를 메모리에 다 로딩하지 않고도 실행할 수 있도록 함
    - 프로그램을 multiple blocks 로 쪼갠다
    - 실행 중 각 시기에 필요한 조각들만 로딩
    - physical memory 용량에 제한 받지 않음

### Benefits

- Easier programming : 프로세스 이미지, 메모리 용량을 신경쓰지 않아도 됨
- Higher multiprogramming degree : 다 가지고 들어가지 않으니 메모리 할당 받는 프로세스의 개수를 늘려줌
- Less I/O for loading and swapping processes into memory : 일부만 들어가 있으니 일부만 빼는 건 쉬움

### Drawbacks

- Address mapping overhead : run-time binding, cpu가 메모리에 접근할 때마다 mapping 해줘야 함
- Page fault handling overhead : 메모리에 없는 다른 조각을 찾으면 I/O 발생 → sleep → overhead
- Should be carefully used in real-time (embedded) systems

### 프로세스간의 페이지 공유

- 시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있도록 한다
- 각 프로세스들은 공유 라이브러리를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다
- 프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있다. 이 또한, 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다
- fork() 를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다 - Copy on write(COW)

### Demand Paging(요구 페이징)

- 초기에 필요한 페이지만 적재하는 전략
- 실행과정에서 필요해질 때 페이지들이 적재된다
- 프로세스 내의 개별 페이지들은 페이저(pager)에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어 옮으로써, 사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다
- 유효, 무효 비트()

### 페이징 시스템

- **PMT(Page Map Table)**
    - PCB에 위치
    - Direct Mapping
        - 가상 주소를 물리 주소로 변환하기 위해 메모리를 접근해야 하므로 총 메모리 접근이 두 배로 일어남
        
        ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/52e1e2e3-e481-43db-b0ce-32c5b2931a2d/Untitled.png)
        
    - Associative mapping
        - TLB(Translation Look-aside Buffer)
            - MMU의 캐시 개념, 주소를 변환할 때 우선 검색
            - key값 기반으로 search, 그걸 parallel, H/W로

### 페이지 교체

> page fault(페이지 부재)가 발생하게 되면, 원하는 페이지를 보조기억장치에서 가져오게 된다. 하지만, 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 이루어져야 한다
> 

**페이지 교체 알고리즘**

- FIFO
    - 장점
        - 쉬움
    - 단점
        - 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있음(초기 변수 등)
        - 처음부터 활발하게 사용된 페이지를 교체해서 페이지 부재율을 높일 수 있음
        - Belady의 모순: 페이지를 저장할 수 있는 페이지 프레임의 개수를 ㅡㄴㄹ려도 되려 페이지 부재가 더 많이 발생하는 모순
- 최적 페이지 교체(Optimal Page Replacement)
    
    앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체
    
    - 장점
        - 알고리즘 중 가장 낮은 페이지 부재율 보장
    - 단점
        - 비현실적
- LRU (Least-Recently-Used)
    
    가장 오랫동안 사용되지 않은 페이지 교체
    
    - 특징
        - 대체적으로 FIFO보다 우수하고, OPT보다는 그렇지 않다
- LFU (Least-Frequently-Used)
    
    참조 횟수가 가장 적은 페이지 교체
    
    - 특징
        - 특정 페이지를 집중적으로 사용하다, 다른 기능을 사용하게 되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다
        - OPT에 제대로 근사하지 못하기 때문에, 잘 안쓰임
- MFU (Most-Frequently Used)
    
    참조 횟수가 가장 작은 페이지가 최근에 메모리에 올라왔고, 앞으로 계속 사용될 것이라는 가정에 기반
    
    - 특징
        - OPT에 제대로 근사하지 못하기 때문에, 잘 안쓰임
- 클럭 알고리즘 (NRU: Not Recently Used, NUR: Not Used Recently)
    - 하드웨어적인 지원을 받아 LRU와 LFU 알고리즘에서 발생한 시간적인 오버헤드를 줄인 방식
    - LRU를 근사시킨 알고리즘이라고 하며, 오랫동안 사용하지 않은 페이지 중 하나를 교체
    - 최근에 참조되지 않은 페이지를 교체 대상으로 선정하는 측면에서 LRU와 비슷하지만 교체되는 페이지의 참조 시점이 가장 오래됐다는 것을 보장하지 못한다
    - 참조 비트(Reference Bit)와 변형 비트(Modified Bit, Dirty Bit)를 사용
        - 참조 비트
            - 페이지가 참조될 때, 1로 자동 세팅, 주기적으로 리셋
            - 페이지가 참조되지 않았을 때는 0이 되며 페이지는 교체
        - 변형 비트
            - 페이지의 내용이 변경되었을 때, 1로 지정
            - 페이지의 내용이 변경되지 않았을 때는 0으로 지정
            - update bit이 1인 페이지를 교체할 때는 wirte back을 해야하는데 이를 최대한 미루자
    - 하드웨어의 자원으로 동작하기 때문에 LRU에 비해 교체 페이지의 선정이 훨씬 빠르게 결정
    - 대부분의 시스템에서 페이지 교체 알고리즘으로 클럭 알고리즘을 채택

### 가상 메모리와 MMU

> CPU는 가상 메모리를 다루고, 실제 해당 주소 접근시 MMU 하드웨어 장치를 통해 물리 메모리로 접근
> 
- 하드웨어 장치를 이용해야 주소 변환이 빠르기 때문에 별도의 장치를 둠

**MMU의 메모리 보호**

- 프로세스는 독립적인 메모리 공간을 가져야 되고, 자신의 공간만 접근해야 한다
- 따라서 한 프로세스에게 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 trap을 발생시키며 보호한다
- base와 limit 레지스터를 활용한 메모리 보호 기법
    - base 레지스터는 메모리상의 프로세스 시작주소를 물리주소로 저장
    - limit 레지스터는 프로세스의 사이즈를 저장
    - 안정성을 위해 해당 레지스터는 커널 모드에서만 수정 가능하도록 설계

## IPC (InterProcess Communication)

- 프로세스는 다른 프로세스의 공간을 접근할 수 없다
    - 프로세스들이 서로의 공간을 쉽게 접근할 수 있다면 프로세스 데이터/코드가 바뀔 수 있으니 위험
- 프로세스간 통신이 필요한 이유
    - 성능을 높이기 위해 여러 프로세스를 만들어 동시에 실행할 경우 이때 프로세스 간 상태 확인 및 데이터 송수신이 필요
1. PIPE(익명 파이프)
    - 두 프로세스간 파이프를 연결해서 통신
    - 한 프로세스는 쓰기만 가능하고 다른 프로세스는 읽기만 가능하다
    - 한쪽 방향으로만 통신 → 반이중 통신
    - 간단하게 사용할 수 있다
2. Named PIPE (FIFO)
    - PIPE는 통신하는 프로세스가 명확할 경우 사용하는 반면, Named PIP는 전혀 모르는 사이의 프로세스들의 통신에 사용
    - 익명 PIPE는 부모가 동일한 프로세스들 사이에서만 통신이 가능하지만 Named PIPE는 부모 프로세스에 관계없이 프로세스들 사이의 통신을 할 수 있다는 점이 특징 → mkfifo함수를 이용해 파일을 생성하기 때문에 가능
    - 익명 PIPE와 동일하게 동시에 읽기/쓰기가 불가능
    - 이는 두 개의 파일을 읽기 전용, 쓰기 전용으로 만들어서 해결할 수 있음
3. 메세지 큐
    - 선입선출 → Named PIPE와 동일
    - 차이점은 Named PIPE가 데이터의 흐름이라면 메세지 큐는 메모리 공간이라는 점??
    - 이는 여러개의 프로세스가 메세지 큐의 데이터에 접근할 수 있음을 의미 ??
4. 공유 메모리
    - 위 세개는 통신을 이용해 데이터를 주고 받는다면, 공유 메모리는 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 지원
    - 프로세스가 공유 메모리 할당을 커널에 요청하면 커널은 해당 프로세스에 메모리 공간을 할당
    - 이후 어떤 프로세스건 해당 메모리 영역에 접근할 수 있다
    - 공유 메모리는 곧바로 메모리에 접근할 수 있기 때문에 IPC 방식 중 속도가 제일 빠르다
5. 메모리 맵
    - 공유 메모리와 메모리를 공유한다는 점은 동일
    - 하지만, 현재 열려져 있는 파일을 공유하는 점에서 차이가 있음
    - 열린 파일이 메모리에 올라가 있으면 다른 프로세스가 해당 파일을 사용할 때 또 다시 파일을 열지 않고 공유한 상태로 사용하는 것이 더 효율적
6. 소켓
    - 소켓을 만들어 통신
    - 소켓 통신은 데이터 교환을 위해 양쪽 PC에서 각각 임의의 포트를 정하고 해당 포트 간의 대화를 통해 데이터를 주고받는 방식. 이 때 각각 PC의 프로세스는 임의의 PORT를 맡아 데이터를 송수신
7. RPC (Remote Procedure Call)
    - 원격 프로시저 호출은 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행 할 수 있게 하는 프로세스간 통신 기술
    - 분산 컴퓨팅 환경에서 많이 사용됐으며, 현재는 MSA에서 마이크로 서비스간에 많이 사용함
    - 서로 다른 환경이지만 서비스간의 프로시저 호출을 가능하게 해줌에 따라 언어에 구애받지 않고 환경에 대한 확장이 가능하며, 좀 더 비즈니스 로직에 집중하여 생산성을 증가시킬 수 있다
    - gRPC (ProtocolBuffer) by Google

## 사용자 스레드 커널 스레드
출처
[https://velog.io/@taehee-kim-dev/사용자-수준-스레드-커널-수준-스레드](https://velog.io/@taehee-kim-dev/%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%A4%80-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%BB%A4%EB%84%90-%EC%88%98%EC%A4%80-%EC%8A%A4%EB%A0%88%EB%93%9C)
[https://m.blog.naver.com/whdgml1996/222076116487](https://m.blog.naver.com/whdgml1996/222076116487)
[https://velog.io/@recordsbeat/스레드-도대체-무엇이길래](https://velog.io/@recordsbeat/%EC%8A%A4%EB%A0%88%EB%93%9C-%EB%8F%84%EB%8C%80%EC%B2%B4-%EB%AC%B4%EC%97%87%EC%9D%B4%EA%B8%B8%EB%9E%98)
[https://medium.com/@unmeshvjoshi/how-java-thread-maps-to-os-thread-e280a9fb2e06](https://medium.com/@unmeshvjoshi/how-java-thread-maps-to-os-thread-e280a9fb2e06)
[https://ahnyezi.github.io/os/OS-4/](https://ahnyezi.github.io/os/OS-4/)

### 사용자 수준 스레드

- 사용자가 스레드 관련 라이브러리로 구현해 사용하는 스레드
- 스레드 관련 모든 행위를 사용자 영역에서 하기 때문에, 커널은 사용자 수준 스레드의 존재를 알지 못하고, 스레드 교환에 개입하지 않는다
- 사용자 수준 스레드 N개가 커널 수준 스레드 1개에 매핑되므로, 다대일 스레드 매핑이라고 한다

**장점**

1. 커널 독립적으로 스케줄링을 할 수 있어 모든 운영체제에 적용 가능, 이식성이 높다
2. 스케줄링이나 동기화를 위해 커널을 호출하지 않으므로, **커널 영역으로 전환하는** 오버헤드가 줄어든다
3. 커널이 아닌 스레드 라이브러리에서 스레드 스케줄링을 제어하므로, 유연한 스케줄링이 가능하다

**단점**

1. 하나의 프로세스로 부터 할당된 여러개의 스레드들 중, 한 스레드가 대기 상태가 되면, 모든 스레드를 실행시킬 수 없게 된다 (커널의 입장에서는 하나의 스레드이므로 여러개 중 하나라도 입출력 등을 하면 '너 I/O 하는 구나? block으로 가있어' 하고 다같이 보내버림)
2. 커널이 스레드 관리에 개입하지 않으므로, 스레드 간 보호에 커널의 보호 방법을 사용할 수 없다. 라이브러리 수준의 보호 방법까지만 사용 가능하다

### 커널 수준 스레드

- 커널이 스레드와 관련된 모든 작업을 관리하는 방식
- 사용자 수준 스레드와 커널 수준 스레드가 1대1로 매핑
- 커널이 직접 스케줄링하고 실행하기 때문에 커널의 관리 지원을 많이 받을 수 있지만, 그 만큼 오버헤드가 늘어난다
- 하지만 커널이 각 스레드들을 개별적으로 관리할 수 있으므로, 동일한 프로세스에서 할당된 여러개의 스레드들 중 한 스레드가 대기상태가 되더라도, 다른 스레드들은 실행시킬 수 있다

### Java Thread는 커널 수준

- Java로 만들어진 프로그램에서는 쓰레드 생성 및 GC에 대한 비용을 줄이기 위해서 Thread Pool을 만드는 방식을 사용
- Java API는 운영체제에 맞는 쓰레드 구현을 추상화 해서 Java에서 쓰레드를 만들어 사용하도록 함
- OS는 C와 C++의 세상이다. OS에게 thread를 할당받기 위해서는 그들의 언어로 이야기 해주어야 한다. JVM은 JNI라는 통역사를 통해 자신에게 thread가 필요하다고 알려준다
- Windows API 이용, 유닉스 계열은 Pthread → OS의 스케줄링 정책을 따름
- 쓰레드의 구현 방식은 OS에 종속적이며 스케줄링 정책 또한 동일

### 디스크 스케줄링 알고리즘

**디스크 물리적 구조**

- platter, track, sector & cylinder, spindle, arm
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/28982bad-1aa2-4778-b2a3-b90411739708/Untitled.png)
    

**디스크 접근 시간**

Seek TIme이 가장 큼. 스케줄링 알고리즘도 헤드의 이동 거리를 줄이는 것이 가장 중요한 목표 

- 탐색 시간(Seek Time)
    - 디스크 헤드를 해당 실린더로 이동하는데 걸리는 시간
- 회전 지연 시간(Rotational Latency Time)
    - 디스크가 회전해서 읽고 쓰려는 섹터가 헤드 위치에 도달하기까지 걸리는 시간
- 전송 시간(Transfer Time)
    - 해당 섹터가 헤드 위치에 도달한 후 데이터를 실제로 섹터에 읽고 쓰는데 소요되는 시간
1. FCFS(First Come First Served)
    - 장점: 기법이 단순하며, 공평하게 요청을 처리
    - 단점: 비효율적
2. SSTF(Shortedst Seek Time First)
    
    현재 헤드에서 가장 가까운 트랙의 요청을 먼저 처리
    
    - 장점: Seek Time이 적다. 즉 트랙을 찾는 시간을 최소화, 처리량(Throughput)을 극대화
    - 단점: 안쪽 및 바깥쪽에 있는 요청들은 기아 현상이 발생할 수도 있다. 응답 시간의 편차가 크다
3. SCAN
    
    헤드셋의 진행방향에 있는 요청을 처리하고, 다시 반대 방향으로 틀어 반대방향에 있는 요청들을 처리
    
    - 장점: SSTF의 바깥쪽 트랙의 기아 가능성을 제거할 수 있고, 응답시간의 편차를 줄일 수 있다
    - 단점: 양 쪽 끝 트랙이 가운데 위치한 트랙보다 대기 시간이 길어짐
4. C-SCAN(Circular Scan)
    
    항상 한쪽 방향에서 반대방향으로 진행하며 트랙의 요청을 처리
    
    SCAN과 다르게 중간에 치고 들어오는 요청이 있어도 요청을 처리하지 않고 큐에 모았다가 일전에 요청한 것들을 다 처리한 후 처리
    
    - 장점: 응답시간의 편차가 매우 적음, SCAN보다 시간 균등성이 좋음
    - 단점: 안쪽이나, 바깥쪽으로 처리할 요청이 없어도 헤드셋이 끝까지 이동하기 때문에 비효율적
5. LOOK, C-LOOk
    
    SCAN과 C-SCAN을 보완. 요청이 진행 방향에서 더이상 없다면, 끝단까지 가지 않고 반대방향으로 가던가(SCAN), 다시 C-SCAN 처음으로
    
    - 장점: 불필요한 헤드 이동시간 제거
    - 단점: 끝단까지 가야할지 말아야 할지 판단하는데 있어서 오버헤드 발생
6. N-STEP SCAN
    - SCAN 기법에 기초. 시작하기 전에 대기하고 있는 요청들을 우선적으로 처리
    - 처리하는 과정 중에 요청이 들어오는 것들은 이후에 모아서, 반대방향으로 진행할 때 서비스
    - 장점: SSTF, SCAN 보다 응답시간의 편차가 적음, 특정 방향에서의 많은 요청으로 인해 반대 방향에 들어온 요청들에 대해 기아현상을 방지할 수 있음

출처
[https://limkydev.tistory.com/165?category=974040](https://limkydev.tistory.com/165?category=974040)
[https://wansook0316.github.io/cs/os/2020/04/06/운영체제-정리-20-디스크-스케줄링-알고리즘.html](https://wansook0316.github.io/cs/os/2020/04/06/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EC%A0%95%EB%A6%AC-20-%EB%94%94%EC%8A%A4%ED%81%AC-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html)
[https://eunhyejung.github.io/os/2018/07/30/operatingsystem-study17.html](https://eunhyejung.github.io/os/2018/07/30/operatingsystem-study17.html)

## 인터럽트
출처
fast campus 운영체제 - 인터럽트 란 / 이준희 강사님
[https://velog.io/@adam2/인터럽트](https://velog.io/@adam2/%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8)

> CPU가 프로그램을 실행하고 있을 때, 입출력 하드웨어 드으이 장치나 또는 예외상황이 발생하여 처리가 필요할 경우에 CPU에 알려서 처리하는 기술
> 

### 인터럽트 필요 이유

- 선점형 스케쥴러 구현 :  프로세스 running 중에 스케쥴러 코드를 실행
    - 타이머 인터럽트 (하드웨어로 부터 일정 시간마다 타이머 인터럽트를 운영체제에 알려줌)
    - 운영체제가 타이머 인터럽트 발생 횟수를 기억해서 5번 타이머 인터럽트가 발생하면, 현재 프로세스를 다른 프로세스로 바꿔준다
- IO Device와의 커뮤니케이션 : 저장매체에서 데이터 처리 완료시, 프로세스를 깨워야 함 (block → ready)
- 예외 상황 핸들링 : 0으로 나누기(Divide-by-Zero Interrupt) 등

### 인터럽드 종류

- 내부 인터럽트
    - Trap이라고 부르며, 주로 프로그램 내부에서 잘못된 명령 또는 잘못된 데이터 사용 시 발생
        - 0 으로 나눴을 때
        - 사용자 모드에서 허용되지 않은 명령 또는 공간 접근 시
        - 계산 결과가 Overflow/Underflow 날 때
- 외부 인터럽트
    - 주로 하드웨어에서 발생
        - 전원 이상
        - 기계 문제
        - 키보드 등 IO관련 이벤트
        - Timer 이벤트
- 소프트웨어 인터럽트 (시스템 콜 인터럽트)
    - 프로그램 처리 중 명령의 요청에 의해 발생한 것 (SVC 인터럽트)
    - 시스템 콜 실행을 위해서는 강제로 코드에 인터럽트 명령을 넣어, CPU에게 실행시켜야 한다
        - 실제 코드
        
        ```c
        mov eax, 1 // 시스템 콜 번호
        mov ebx, 0 // 시스템 콜에 해당하는 인자값
        int 0x80.  // 소프트웨어 인터럽트 명령 (system_call())
        ```
        
        - 인터럽트 명령을 호출하면서 0x80 값을 넘겨줌 → CPU는 사용자 모드를 커널 모드로 바꿔줌 → IDT(Interrupt Descriptor Table)에서 0x80에 해당하는 (주소)함수를 찾아서 실행함 → system_call() 함수에서 eax로 부터 시스템 콜 번호를 찾아서, 해당 번호에 맞는 시스템 콜 함수로 이동 → 함수 실행 후 다시 사용자 모드로 변경

### 인터럽트 발생 처리 과정

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/24e96a65-8fd9-401d-ae91-d06938fa2e3e/Untitled.png)

- 관련 용어
    - 인터럽트 핸들러
        - 실제 인터럽트를 처리하기 위한 루틴으로 인터럽트 서비스 루틴이라고도 한다
        - 운영체제의 코드 영역에는 인터럽트 별로 처리해야 할 내용이 이미 프로그램되어 있다
    - 인터럽트 벡터
        - 인터럽트 발생 시 처리해야 할 인터럽트 핸들러의 주소를 인터럽트 별로 보관하고 있는 테이블
    - PCB
        - 인터럽트 발생 시 수행 중이던 memory 주소, 레지스터 값, 하드웨어 상태 등 저장











## 캐시의 지역성

> 속도가 빠른 장치와 느린 장치에서 손도 차이에 따른 병목 현상을 줄이기 위한 메모리
> 

ex1) CPU 코어와 메모리 사이의 병목 현상 환와

ex2) 웹 브라우저 캐시 파일은, 하드디스크와 웹페이지 사이의 병목 현상을 완화

### Caches

- CPU는 2~3개 정도의 캐시 메모리가 사용됨
- 듀얼 코어 프로세서의 캐시 메모리 :  각 코어마다 독립된 L1 캐시 메모리를 가지고, 두 코어가 공유하는 L2 캐시 메모리가 내장됨
- L1, L2, L3 Cache(SRAM)
    - L1 Cache : CPU 내부에 존재, 프로세스와 가장 가까운 캐시, 속도를 위해 I$와 D$로 나뉜다
        - Instruction Cache (I$) : 메모리의 TEXT 영역 데이터를 다루는 캐시
        - Data Cache (D$) : TEXT 영역을 제외한 모든 데이터를 다루는 캐시
    - L2 Cache : CPU와 RAM 사이에 존재, 용량이 큰 캐시, 크기를 위해 L1 캐시 처럼 나누지 않는다
    - L3 Cache : 보통 메인보드에 존재, 멀티 코어 시스템에서 여러 코어가 공유하는 캐시
- 디스크 캐시: 주기억장치(RAM)와 보조기억장치(HDD) 사이에 존재하는 캐시

### 캐시 메모리 작동 원리

- 시간 지역성
    - for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시 후 다시 참조될 가능성이 높음
- 공간 지역성
    - A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시 후 다시 사용될 가능성이 높음
- 캐시에 데이터를 저장할 때는, 참조 지역성(공간)을 최대한 활용하기 위해 해당 데이터 뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다
- CPU가 요청한 데이터가 캐시에 있으면 'Cache Hit', 없어서 DRAM에서 가져오면 'Cache Miss'

### 캐시 미스 3가지 경우

- Cold miss : 해당 메모리 주소를 처음 불러서 나는 미스
- Conflict miss : 캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스 (direct mapped cache에서 많이 발생)
- Capacity miss : 캐시 메모리의 공간이 부족해서 나느 미스 (Conflict는 주소 할당 문제, Capacity는 공간 문제)
- 캐시 크기를 키워서 문제를 해결하려하면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점이 생김

### Cache Metrics

- 캐시의 성능을 측정할 때는 Hit latency와 Miss latency가 중요한 요인으로 꼽힘
- 평균 접근 시간 : Average access tiem = Hit latency  + Miss rate * Miss latency

### 구조와 작동 방식

1. Direct mapped Cache
    - DRAM의 여러 주소가 캐시 메모리의 한 주소에 대응되는 다대일 방식
    - 메모리 주소를 인덱스 필드와 태그 필드로 나누어 인덱스 필드를 캐시 메모리 주소에 맵핑
    - 인덱스 필드 + 태그 필드 + 데이터 필드
    - 단점 : Conflict Miss 발생
2. Fully Associative Cache
    - 비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식
    - 저장할 때는 매우 간단하지만, 찾을 때가 문제
    - 조건이나 규칙이 없어서 특정 캐시 Set 안에 있는 모든 블럭을 한번에 찾아 원하는 데이터가 있는지 검색
    - CAM이라는 특수한 메모리 구조를 사용해야 하지만 가격이 매우 비싸다
3. Set Associative Cache
    - Direct + Fully 방식
    - 특정 행을 지정하고, 그 행안의 어떤 열이든 비어있을 때 저장하는 방식
    - Direct에 비해 검색 속도는 느리지만, 저장이 빠르고 Fully에 비해 저장이 느린 대신 검색이 빠른 중간형
    - 인덱스가 가리키는 공간이 두 개 이상, n-way set associative 캐시라고 부름

### Handling Cache writes

- Write-through
    - 캐시에 데이터가 작성될 때마다 메모리의 데이터를 업데이트
- Write-back
    - 블록이 교체될 때만 메모리의 데이터를 업데이트
    - dirty 비트를 추가하여 교체될 때 dirty 비트가 1이면 메모리의 데이터를 변경

상세 설명: [https://parksb.github.io/article/29.html](https://parksb.github.io/article/29.html)

## 컴파일러

- 초기 컴퓨터 프로그램들은 어셈블리어로 작성
    - 서로 다른 CPU아키텍쳐가 등장할 때마다 매번 똑같은 프로그램 작성(최적화지만 이식성이 떨어짐)
    - 어셈블리어로는 프로그램 작성 속도가 매우 떨어짐(작업 속도)
    - 리눅스의 경우 CPU별로 컨텍스트 스위칭 코드가 존재
- 컴파일러
    - CPU아키텍쳐에 따라서는 컴파일러 프로그램만 만들면 되고, 기존 코드는 수정할 필요가 없다(이식성 증가)
    - 어셈블리어로 작성한 코드보다는 작동 속도가 떨어질 수 있다
- 컴파일 과정
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e6bbde50-f6af-48cc-b34c-73480faa4a87/Untitled.png)
    

출처
[https://openingsound.tistory.com/m/107?category=1171777](https://openingsound.tistory.com/m/107?category=1171777)
[https://st-lab.tistory.com/176](https://st-lab.tistory.com/176)

## 컴파일, 인터프리터, 하이브리드

[https://st-lab.tistory.com/176](https://st-lab.tistory.com/176)

## 메모리 단편화(파편화)

> RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용 가능한 메모리가 충분히 존재하지만 할당이 불가능한 상태
> 

### 단편화의 종류

1. 내부 단편화
    - 메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비
2. 외부 단편화
    - 메모리가 할당되고 해제되는 작업이 반복될 때, 중간 중간 생긴 작은 메모리 공간이 생긴다. 메모리 전체적으로 보았을 때는 충분한 여유공간이 있지만, 프로세스가 필요로하는 메모리양 만큼의 연속된 공간이 없어서 메모리를 할당하지 못하는 상황

### 메모리 단편화 해결방법

1. 페이징(Paging) 기법 (가상 메모리 사용, 외부 단편화 해결, 내부 단편화 존재)
    - 논리(가상)메모리는 페이지(Page)라고 불리는 고정 크기의 블록으로 나뉘어지고, 물리 메모리는 프레임(Frame)이라 불리는 페이지와 같은 크기의 블록들로 나위어짐. 보조 메모리 역시 프레임과 같은 크기의 블록들로 나뉘어짐
    - 할당은 항상 프레임의 정수 배로 할당, 이 때 프로세스가 페이지 경계와 일치하지 않는 크기의 메모리를 요구하게 되면 마지막 페이지 프레임은 전부 사용되지 않고 남아버리는 문제 발생 (내부 단편화)
    - 페이징 기법을 사용하면 연속적이지 않은 공간으로 메모리를 할당할 수 있기 때문에 외부 단편화 해결
    - 페이지 단위를 작게하면 내부 단편화 문제도 해결할 수 있겠지만 대신 page mapping 과정이 많아지므로 오히려 효율이 떨어질 수 있음
2. 세그멘테이션(Segmentation) 기법 (가상 메모리 사용, 내부 단편화 해결, 외부 단편화 존재)
    - 세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈 공간을 찾아서 할당
    - 가상 메모리를 서로 다른 크기의 논리적 단위인 세그먼트로 분할해서 메모리 할당
    - 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 자유 공간들이 많은 수의 작은 조각들로 나뉘어져 못 쓰게 될 수도 있다 (외부 단편화)
3. 메모리 풀(Memory Pool)
    - 필요한 메모리 공간을 필요한 크기, 개수 만큼 사용자가 직접 지정하여 미리 할당받아 놓고 필요할 때마다 사용하고 반납하는 기법
    - 랜덤한 위치에 할당과 해제를 반복하여 단편화를 일으키는 것이 아니라
    - 미리 공간을 할당해놓고 가져다 쓰고 반납하기 때문에 할당과 해제로 인한 외부 단편화가 발행하지 않는다
    - 또한 필요한 크기만틈 할당을 해놓기 때문에 내부 단편화 또한 생기지 않는다
    - 하지만 메모리 단편화로 인한 메모리 낭비량보다 메모리 풀을 만들었지만 쓰지 않았을 때 메모리 양이 커질 경우 사용하지 않아야 한다
    - 메모리 할당, 해제가 잦은 경우에 메모리 풀을 쓰면 효과적
    - 미리 할당해놓고 사용하지 않는 순간에도 계속 할당해놓으므로 메모리 누수가 있는 방식
    
    구현 방법
    
    - 큰 메모리 블록(페이지)을 힙으로 부터 할당
    - 할당 받은 페이지를 각 객체의 크기의 블록으로 나눔
    - 각 객체를 위한 블록을 순차적으로 링크
    - 이 때 현 시점에서 할당할 블록을 특정 포인터가 가리키게 함
    - 메모리 요청이 생기면 현재 헤더 포인터가 가리키는 블록을 돌려준다
    - 할당이 일어난 후 헤더 포인터는 할당 직전에 가리키던 블록이 가리키던 블록을 가리킨다 (링크드 리스트 처럼?)
    - 사용되던 메모리가 해제되어 메모리 풀로 돌아올 경우 헤더 포인터는 그 블록을 가리키고 장금 전까지 헤더 포인터가 기리키던 블록을 돌아온 블록의 당므 포인터가 가리키게 한다

출처: [https://jeong-pro.tistory.com/91](https://jeong-pro.tistory.com/91)

Kernel Memory

- 사용자 모드의 프로세스가 추가적인 메모리를 요구하면 커널 페이지 프레임을 넘겨줌
- 커널 메모리의 특징
    - 사용자 모드 프로세스와 달리 메모리 풀에서 할당하는 정책 사용
    - 커널은 다양한 자료구조를 사용하지만 대충 필요한 메모리의 양이 정해져 있기에 이를 고려하고 적절히 할당됨
    - 일반 프로세스의 페이지는 연속적일 필요가 없으나 커널은 하드웨어와 직접 상호작용하기에 물리적으로 연속적인 페이지 프레임을 할당 받음

Buddy, Slab allocator...

## 가상화
출처
[https://www.notion.so/65fc5413d93547319ac07051aac8c6cd](https://www.notion.so/65fc5413d93547319ac07051aac8c6cd)

### 가상화란?

가상화는 하이퍼바이저(Hypervisor)라고 하는 소프트웨어를 사용하여 하나의 물리적 하드웨어에 다수의 가상머신을 만드는 기술

### 왜 가상화를 사용하는가?

- 효율성
    - 물리적 서버 구성 및 유지보수 측면에서 비용 절감
    - 단일 물리 서버에서 다수의 가상 서버에 대한 통합 관리 가능
- 안정성
    - 가상 머신 스냅샷을 통한 데이터 백업, 복구, 자동화 가능
- 전략성
    - 쉬운 백업, 복구 자동화로 가상머신을 이용한 테스트가 쉬움

### 가상화의 종류

1. 호스트 가상화
    - Base가 되는 Host OS 위에 Guest OS가 구동되는 방식
    - 장점: 가상의 하드웨어를 에뮬레이팅하기 때문에 호스트 운영체제에 크게 제약사항이 없음
    - 단점: OS 위에 OS가 얹히는 방식이기 때문에 오버헤드가 클 수 있음
    - 종류: VMware Server, Virtual Box
2. 하이퍼바이저 가상화
    - Host OS 없이 하드웨어에 하이퍼바이저를 설치하여 사용하는 방식
    - 장점: 별도의 Host OS가 없기 때문에 오버헤드가 적고, 하드웨어를 직접 제어하기 때문에 효율적으로 리소스를 사용할 수 있음
    - 단점: 자체적으로 머신에 대한 관리 기능이 없기 때문에 관리를 위한 컴퓨터나 콘솔이 필요
    
    **전가상화와 반가상화**
    
    - 전가상화
        - 하드웨어를 완전히 가상화하는 방식
        - 기존의 OS의 리소스 경유를 하지 않기 때문에 처리 오버헤드가 발생하지 않게 된다
        - 하이퍼바이저를 구동하면 DOM0라고 하는 관리용 가상머신이 실행되며, 모든 가상 머신들의 하드웨어 접근이 DOM0를 통해서 이루어진다
        - 하이퍼바이저가 Guest OS들의 명령을 번역해 하드웨어로 전달하는 역할
        - 하드웨어를 접근하려고 하면 exception 일으켜서 하이퍼바이저 콜 하도록
        - 특징
            - 하드웨어를 완전히 가상화하기 때문에 Guest OS의 튜닝이 필요없다
            - 하이퍼바이저가 모든 명령을 중재하기 때문에 성능이 비교적 느리다
    - 반가상화
        - 하드웨어의 일부만 가상화
        - 전가상화의 가장 큰 단점인 성능 저하의 문제를 해결하기 위해 하이퍼 콜(Hyper Call)이라는 인터페이스를 통해 하이퍼바이저에게 직접 요청할 수 있다
        - 특징
            - 모든 명령을 DOM0를 통해 전달하는 전가상화에 비해 성능이 빠르다
            - 하이퍼바이저에게 Hyper Call 요청을 할 수 있도록 각 Guest OS의 커널을 튜닝할 필요가 있기 때문에 오픈소스 OS가 아니라면 반가상화를 이용하기 쉽지 않다
3. 컨테이너 가상화
    - Host OS 위에 컨테이너 관리 소프트웨어를 설치하여 프로세스를 격리하는 방식의 컨테이너를 사용
    - 컨테이너에는 게스트OS 나 가상하드웨어를 포함하지 않는다
    - 컨테이너는 애플리케이션과 애플리케이션 동작을 위한 라이브러리 등으로 구성되기 때문에 이를 각각 개별 서버처럼 사용이 가능하다
    - 오버헤드가 적어 가볍고 빠르다

## 파일 시스템
출처: fastcampus 이준희 강사님, 운영체제 엄교수님

> 운영체제가 저장매체에 파일을 쓰기 위한 자료구조 또는 알고리즘
> 

### 파일 시스템이 만들어진 이유

1. 블록
    - 블록 단위로 관리 (보통 4KB)
    - 블록마다 고유 번호를 부여해서 관리
2. 파일
    - 사용자가 각 블록 고유 번호를 관리하기 어려움: 추상적(논리적 객체 필요) ⇒ 파일
    - 사용자는 파일단위로 관리, 각 파일에는 블록 단위로 관리
3. 저장  방법
    - 저장 매체에 효율적으로 저장
    - 외부 단편화, 파일 사이즈 변경 문제로 불연속 공간에 파일 저장 기능 지원 필요
4. 참고: 다양한 파일 시스템
    - Windows: FAT, FAT32, NTFS: 블록 위치를 FAT라는 자료 구조에 기록 (Linked list)
    - 리눅스(UNIX): ext2, ext3, ext4: 일종의 인덱스 블록 기법인 inode 방식 사용 (index)

### 파일 시스템과 시스템 콜

- 동일한 시스템 콜을 사용해서 다양한 파일 시스템 지원 가능토록 구현
    - 파일을 실제로 어떻게 저장할지는 다를 수 있음
    - 리눅스의 경우 ext4 외 NTFS, FAT32 파일 시스템 지원

### inode 방식 파일 시스템

- 파일 시스템 기본 구조
    - 수퍼 블록: 파일 시스템 정보
    - inode 블록: 파일 상세 정보, FCB(File Control Block)
    - 데이터 블록: 실제 데이터
- inode 와 파일
    - '파일이름:inode' 로 파일 이름은 inode 번호와 매칭
    - 파일 시스템에서는 inode 를 기반으로 파일 엑세스
    - inode에 기반 메타 데이터 저장
- inode 구조
    - inode 기반 메타 데이터: 파일 권한, 소유자 정보, 파일 사이즈, 생성시간 등 시간 관련 저옵, 데이터 저장 위치 등
    - Direct blocks - 12개의 4KB 블록
    - Single indirect - 4KB 하나에 direct block pointer를 모아놓음 = 4KB / 4byte = 1024개
    - Double indirect - single indirect pointer를 담고 있음
    - Triple infirect - d 를 담고 잇음

### 가상 파일 시스템 (Virtual File System)

- Network 등 다양한 기기도 동일한 파일 시스템 인터페이스를 통해 관리 가능
- 끊김없이 하나의 파일 시스템처럼 보이게하고 다 접근할 수 있도록

### 기타

- open-file table
    - 파일을 open 할 때, FCB에 있는 메타 데이터를 읽어서 메타데이터를 읽어 kernel data structure에 저장
    - 매번 메타 데이터를 찾아오지 않고 빠르게 접근할 수 있도록
- ELF (Executable and Linking Format)
    - Common standard file format for executables, ex) exe
- Mounting
    - 루트 파일 시스템에 다른 디바이스나 파일 시스템을 연결

### 파일 시스템

- UFS
    - boot block, super block, indoe list, data blocks
    - File access permissions : rwx 9개 + 앞에 3개 (set uid 등) = 12개
    - Directory structure: File name - inode 구조
    - ex2 : data blocks of a file placed in the same Cylinder group
