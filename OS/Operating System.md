## CPU Scheduling

### 스케쥴링

> CPU를 잘 사용하기 위해 프로세스를 잘 배정하기
> 

조건: 오버헤드 ↓ / 사용률 ↑ / 기아 현상 ↓

시스템별 목표

1. Batch System: 가능하면 많은 일을 수행. 시간(time) 보단 처리량(throughout)이 중요
2. Interactive System: 빠른 응답 시간, 적은 대기 시간
3. Real-time System: 기한(deadline) 맞추기

### 스케쥴러

프로세스 스케쥴링을 위한 Queue

- Job Queue: 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device Queue: Device I/O 작업을 대기하고 있는 프로세스의 집합

각각의 Queue에 프로세스들을 넣고 빼주는 스케쥴러에도 크게 세 가지 종류가 존재

1. 장기스케쥴러 (Long-term scheduler or job scheduler)
    - 한정된 메모리, 많은 프로세스가 한꺼번에 메모리에 올라올 경우 → 대용량 메모리에 임시로 저장
    - 이 pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue로 보낼지 결정하는 역할
    - 메모리에 프로그램이 너무 많아도, 너무 적어도 성능은 떨어짐. 참고로 time sharing system에서는 장기 스케쥴러가 없다
    - 프로세스 상태: new → ready(in memory)
2. 단기스케쥴러 (Short-term scheduler or CPU scheduler) 
    - CPU와 메모리 사이의 스케쥴링을 담당
    - Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정 (scheduler dispatch)
    - 프로세스의 상태 : ready -> running -> waiting -> ready
3. 중기스케쥴러 (Medium-term scheduler or Swapper)
    - 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swapping)
    - Unix나 Window에서는 장기 스케쥴러가 거의 사용되지 않는다
    - 프로세스 상태 : ready → suspended
- Process state
    - Suspended(stopped): 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 Swap out 된다
    - Blocked : 다른 I/O  작업을 기다리는 상태이기 대문에 스스로 ready state로 돌아갈 수 있지만, suspended 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다
- 장기 vs 단기
    - 단기스케쥴러는 상당히 빨라야 하고 호출 빈도수가 많다
    - 새로운 작업이 생성되어 들어오는 것은 분 단위로 장기는 호출 빈도수가 단기에 비해 매우 적다 → 장기는 시간이 꽤 걸리더라도 신중하게 프로세스를 선택
    - 장기가 I/O 프로세스나 CPU 중심 프로세스 중 한쪽으로만 편중해서 받아오면 ready queue, device queue 한쪽에 프로세스가 집중되어 단기의 균형도 붕괴된다

### 선점 / 비선점 스케쥴링

- 선점 (preemptive) : OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우
- 비선점 (nonpreemptive) : 프로세스 종료 or I/O 등의 이벤트가 있을 때까지 실행 보장 (처리 시간 예측 어려움)

### 프로세스 상태

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ab549490-5e0a-4805-9be5-4506ef2b25d7/Untitled.png)

- 비선점 스케쥴링: Interrupt, Scheduler Dispatch
- 선점 스케쥴링: I/O or Event Wait
- 프로세스의 상태 전이
    - 승인(Admitted) : 프로세스 생성이 가능하여 승인됨
    - 스케쥴러 디스패치(Scheduler Dispatch) : 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것
    - 인터럽트(Interrupt) : 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것
    - 입출력 또는 이벤트 대기(I/O or Event wait) : 실행 중인 프로세스가 입출력이나 이벤트를 처리해야 하는 경우, 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것
    - 입출력 또는 이벤트 완료(I/O or Event Completion) : 입출력/이벤트가 끝난 프로세스를 준비 상태로 전환하여 스케쥴러에 의해 선택될 수 있도록 만드는 것

### CPU 스케쥴링의 종류

- 비선점 스케쥴링
    1. FCFS (First Come First Served)
        - 큐에 도착한 순서대로 CPU 할당
        - 실행 시간이 짧은 게 뒤로 가면 평균 대기 시간이 길어짐
        
        문제점
        
        - convoy effect : 소요시간이 긴 프로세스가 먼저 도달하여 효율서을 낮추는 현상
    2. SJF (Shortest Job First)
        - 수행시간이 가장 짧다고 판단되는 작업을 먼저 수행
        - FCFS 보다 평균 대기 시간 감소, 짧은 작업에 유리
        
        문제점
        
        - starvation
        - 비현실적, 프로세스의 CPU 점유 시간(Burst time)을 알 수 없다
    3. HRN (Highest Response-ratio Next)
        - 우선순위를 계산하여 점유 불평등을 보완한 방법 (SJF의 단점 보완)
        - 우선순위 = (대기시간 + 실행시간) / 실행시간
- 선점 스케쥴링
    1. Priority Scheduling
        - 정적/동적으로 우선순위를 부여하여 우선순위가 높은 순서대로 처리
        - 우선순위가 낮은 프로세스가 무한정 기다리는 Starvation이 생길 수 있음
        
        문제점
        
        - starvation, 무기한 봉쇄(Indefinite blocking)
        - Aging 방법으로 Starvation 문제 해결 가능
    2. SRT(Shortest Remaining Time)
        - 현재 CPU에서 실행 중인 프로세스의 남은 CPU burst 시간보다 더 짧은 CPU burst 를 가진 프로세스가 도착하면 CPU가 선점
    3. Round Robin
        - FCFS에 의해 프로세스들이 보내지면 각 프로세스는 동일한 시간의 Time Quantum 만큼 CPU를 할당 받음 (Time Quantum or Time Slice : 실행의 최소 단위 시간, 일반적으로 10~100msec 사이의 범위)
        - n 개의 프로세스가 ready queue에 있고 할당 시간이 q인 경우 각 프로세스는 q 단위로 CPU 시간의 1/n 을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
        - 할당 시간(Time Quantum)이 크면 FCFS와 같게 되고, 작으면 문맥 교환 (Context Switching)이 잦아져서 오버헤드 증가
    4. Multilevel-Queue (다단계 큐)
        - 작업들을 여러 종류의 그룹으로 나누어 여러 개의 큐를 이용하는 기법
        - 우선순위가 낮은 큐들이 실행 못하는 걸 방지하고자 각 큐 마다 다른 Time Quantum을 설정해주는 방식 사용
        - 우선순위가 높은 큐는 작은 Time Quantum 할당, 낮은 큐는 큰 Time Quantum 할당
        
        ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/abe3b5ea-f09f-4d43-aa6f-51413bc16b75/Untitled.png)
        
    5. Multilevel-Feedback-Queue (다단계 피드백 큐)
        - 다단계 큐에서 자신의 Time Queantum을 다 채운 프로세스는 밑으로 내려가고 자신의 Time Quantum을 다 채우지 못한 프로세스는 원래 큐 그대로
            - Time Quantum을 다 채운 프로세스는 CPU burst 프로세스로 판단하기 때문
        - 짧은 작업에 유리, 입출력 위주(Interrupt가 잦은) 작업에 우선권을 줌
        - 처리 시간이 짧은 프로세스를 먼저 처리하기 때문에 Turnaround 평균 시간을 줄여줌?
        - 대부분의 상용 운영체제는 여러 개의 큐를 사용하고 각 큐마다 다른 스케쥴링 방식을 사용

### CPU 스케쥴링 척도

1. Response Time: 작업이 처음 실행되기까지 걸린 시간
2. Turnaround Time: 실행 시간과 대기 시간을 모두 합한 시간으로 작업이 완료될 때 까지 걸린 시간

## 데드락(DeadLock)

기아상태(Starvation) : 여러 프로세스가 부족한 자원을 점유하기 위해 경쟁할 때, 특정 프로세스가 영원히? 자원 할당이 되지 않는 경우 (starvation은 ready에서 무한 대기, deadlock은 asleep에서 무한 대기)

→ 우선 순위 변경으로 해결 (수시 변경, 오래 기다린 프로세스의 순위 상승, Queue 사용)

### 데드락(DeadLock)

> 프로세스가 자원을 얻지 못해서 다음 처리를 하지 못하는 상태
'교착 상태'라고도 부름
시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생
> 

DeadLock : 발생할 일이 아예 없는 이벤트나 자원을 기다리는 것

indefinite postponement : 자원을 할당받지 못하고 계속 지연되고 있음. 하지만 할당받을 가능성이 0은 아님

주로 발생하는 경우

- 멀티 프로그래밍 환경에서 한정된 자원을 얻기 위해 서로 경쟁하는 상황 발생
- 한 프로세스가 자원을 요청했을 때, 동시에 그 자원을 사용할 수 없는 상황이 발생할 수 있음. 이때 프로세스는 대기 상태로 들어감
- 대기 상태로 들어간 프로세스들이 실행 상태로 변경될 수 없을 때 '교착 상태' 발생

### 데드락(DeadLock) 발생 조건

4가지 모두 성립해야 데드락 발생 (하나라도 성립하지 않으면 데드락 문제 해결 가능)

1. 상호 배제 (Mutual exclusion)
    
    자원은 한번에 한 프로세스만 사용할 수 있음
    
2. 점유 대기 (Hold and wait)
    
    최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재함
    
3. 비선점 (No preemption)
    
    다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음
    
4. 순환 대기 (Circular wait)
    
    프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함
    

### 데드락(DeadLock) 처리

교착 상태를 예방 & 회피

1. 예방(prevention)
    
    교착 상태 발생 조건 중 하나를 제거하면서 해결한다 (자원 낭비가 매우 심함)
    
    - 상호배제 부정: 여러 프로세스가 공유 자원 사용 (사실 불가능)
    - 점유대기 부정: 프로세스 실행 전 모든 자원을 할당 (내가 사용하지 않는 구간에도 자원을 점유하고 있어서 비효율적)
    - 비선점 부정: 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가지 자원 반납 (가능은 하지만 선점당한 프로세스가 비정상적으로 종료될 수 있음)
    - 순환대기 부정: 자원에 고유번호 할당 후 순서대로 자원 요구 (r1 > r2: O, r2 > r1: X)
2. 회피(avoidance)
    
    교착 상태가 발생하지 않을 안전 상태를 유지하도록
    
    각 프로세스 별로 자원 최대 요구향이 미리 알려져있어야 함 (비현실적)
    
    은행원 알고리즘 (Banker's Algorithm), Dijksta's alorithm, Habermann's algorithm
    
    - 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지 사전에 검사하여 교착 상태 회피
    - 안정 상태면 자원 할당, 아니면 다른 프로세스들이 자원 해지까지 대기
    
**회피(avoidance)와 탐지(detection)의 차이**
**avoidance**
- considers worst case 
- 최대 요구량까지 요구하는 최악의 경우에도 교착상태에 걸리지 않는 길이 있는가
**detection**
- considers most favorable case
- Checks whether current state has deadlocked processes or not
- Does not consider/respond to the (expected) states in the future
- 최선의 경우, 현재 요청한 리소스만 할당 받으면 그 프로세스는 더이상 요청하지 않을 거야

교착 상태를 탐지 & 획복

교착 상태가 되도록 허용한 다음 회복시키는 방법?

1. 탐지(Detection)
    - 자원 할당 그래프를 통해 교착 상태를 탐지함
    - 자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생함
    - 현재만 교착 상태가 아니면 됨. best case를 바라봄
2. 회복(Recovery)
    
    교착 상태를 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법
    
    프로세스 종료 방법
    
    - 교착 상태의 프로세스를 모두 중지
    - 교착 상태가 제거될 때까지 하나씩 프로세스 중지
    
    자원 선점 방법
    
    - 교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당 (해당 프로세스 일시정지 시킴)
    - 우선 순위가 낮은 프로세스나 수행 횟수 적은 프로세스 위주로 프로세스 자원 선점


## 세마포어(Semaphore)와 뮤텍스(Mutex)의 차이점

공유된 자원의 데이터는 한번에 하나의 프로세스만 접근할 수 있도록 제한해야 함 → 이를 위해 나온 것이 '세마포어'

### 세마포어

- 멀티프로그래밍 환경에서 공유 자원에 대한 접근을 제한하는 방법
- 기존 Mutual Exclusion 기법의 Busy waiting을 방지하기 위한 기법 (다익스트라가 제안)
- 동시에 접근할 수 있는 '허용 가능한 갯수'를 가지고 있는 Counter.
- 세마포어 Counter의 갯수에 따라
    - 1개: Binary Semaphore
        - Mutex
    - 2개 이상: Counting Semaphore
        - Producer-consumer problem
        - Reader-writer problem
        - Dining philosopher problem
- 세마포어는 소유할 수 없다 : 세마포어를 소유하지 않은 스레드가 세마포어를 해제할 수 있는 문제 발생

### 뮤텍스 (Mutal Exclusion)

- 공유된 자원의 데이터를 여러 프로세스, 스레드가 접근하는 것을 막는 것
- 임계 구역을 가진 스레드들의 Running time이 서로 겹치지 않게 각각 단독으로 실행되게 하는 기술
- 뮤텍스 객체를 두 스레드가 동시에 사용할 수 없다
- Lock에 대한 소유권이 있음. Lock을 가진 사람만 반납할 수 있음.
- 무조건 1개의 열쇠

Race condition

- 여러 프로세스가 같은 데이터를 번갈아 가면서 접근하고 조작할 때, 최종 결과가 접근한 순서에 따라 달라지는 것

임계 구역 (Critical Section)

- 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 부분
- 한 프로세스가 임계 구역을 수행할 때는 다른 프로세스가 접근하지 못하도록 해야 한다
- 임계 구역 문제를 해결하기 위한 3가지 필수 조건
    - 상호 배제
    - 진행(Progress) : 임계 구역에서 실행 중인 프로세스가 없고 별도의 동작이 없는 프로세스들만 임계 구역 진입 후보로서 참여될 수 있다. 어떤 프로세스라도 아무도 CS에 없는데 제한되면 안됨
    - 한정된 대기(Bounded Waiting) : 특정 프로세스는 유한한 시도 내에 CS에 들어갈 수 있어야 한다

세마포어 P(), V() 연산 
- indivisible operation (마치 기계어 명령처럼 중간에 인터럽트를 받으면 안됨) 

- P() : wait(), 임계 구역 들어가기 전에 수행 (프로세스 진입 여부를 자원의 개수(S)를 통해 결정)
- V() : signal(), 임계 구역에서 나올 때 수행 (자원 반납 알림, 대기 중인 프로세스를 깨우는 신호)

## 가상 메모리
[https://wogh8732.tistory.com/395?category=807175](https://wogh8732.tistory.com/395?category=807175)

> 다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야 한다
가상메모리는 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이며, 프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있다
> 

### 가상 메모리가 하는 일

가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것으로 정리할 수 있다. 이로써 작은 메모리를 가지고도 얼마든지 큰 가장 주소 공간을 프로그래머에게 제공할 수 있다

### Concept

- 프로세스의 이미지를 메모리에 다 로딩하지 않고도 실행할 수 있도록 함
    - 프로그램을 multiple blocks 로 쪼갠다
    - 실행 중 각 시기에 필요한 조각들만 로딩
    - physical memory 용량에 제한 받지 않음

### Benefits

- Easier programming : 프로세스 이미지, 메모리 용량을 신경쓰지 않아도 됨
- Higher multiprogramming degree : 다 가지고 들어가지 않으니 메모리 할당 받는 프로세스의 개수를 늘려줌
- Less I/O for loading and swapping processes into memory : 일부만 들어가 있으니 일부만 빼는 건 쉬움

### Drawbacks

- Address mapping overhead : run-time binding, cpu가 메모리에 접근할 때마다 mapping 해줘야 함
- Page fault handling overhead : 메모리에 없는 다른 조각을 찾으면 I/O 발생 → sleep → overhead
- Should be carefully used in real-time (embedded) systems

### 프로세스간의 페이지 공유

- 시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있도록 한다
- 각 프로세스들은 공유 라이브러리를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다
- 프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있다. 이 또한, 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다
- fork() 를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다 - Copy on write(COW)

### Demand Paging(요구 페이징)

- 초기에 필요한 페이지만 적재하는 전략
- 실행과정에서 필요해질 때 페이지들이 적재된다
- 프로세스 내의 개별 페이지들은 페이저(pager)에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어 옮으로써, 사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다
- 유효, 무효 비트()

### 페이징 시스템

- **PMT(Page Map Table)**
    - PCB에 위치
    - Direct Mapping
        - 가상 주소를 물리 주소로 변환하기 위해 메모리를 접근해야 하므로 총 메모리 접근이 두 배로 일어남
        
        ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/52e1e2e3-e481-43db-b0ce-32c5b2931a2d/Untitled.png)
        
    - Associative mapping
        - TLB(Translation Look-aside Buffer)
            - MMU의 캐시 개념, 주소를 변환할 때 우선 검색
            - key값 기반으로 search, 그걸 parallel, H/W로

### 페이지 교체

> page fault(페이지 부재)가 발생하게 되면, 원하는 페이지를 보조기억장치에서 가져오게 된다. 하지만, 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 이루어져야 한다
> 

**페이지 교체 알고리즘**

- FIFO
    - 장점
        - 쉬움
    - 단점
        - 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있음(초기 변수 등)
        - 처음부터 활발하게 사용된 페이지를 교체해서 페이지 부재율을 높일 수 있음
        - Belady의 모순: 페이지를 저장할 수 있는 페이지 프레임의 개수를 ㅡㄴㄹ려도 되려 페이지 부재가 더 많이 발생하는 모순
- 최적 페이지 교체(Optimal Page Replacement)
    
    앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체
    
    - 장점
        - 알고리즘 중 가장 낮은 페이지 부재율 보장
    - 단점
        - 비현실적
- LRU (Least-Recently-Used)
    
    가장 오랫동안 사용되지 않은 페이지 교체
    
    - 특징
        - 대체적으로 FIFO보다 우수하고, OPT보다는 그렇지 않다
- LFU (Least-Frequently-Used)
    
    참조 횟수가 가장 적은 페이지 교체
    
    - 특징
        - 특정 페이지를 집중적으로 사용하다, 다른 기능을 사용하게 되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다
        - OPT에 제대로 근사하지 못하기 때문에, 잘 안쓰임
- MFU (Most-Frequently Used)
    
    참조 횟수가 가장 작은 페이지가 최근에 메모리에 올라왔고, 앞으로 계속 사용될 것이라는 가정에 기반
    
    - 특징
        - OPT에 제대로 근사하지 못하기 때문에, 잘 안쓰임
- 클럭 알고리즘 (NRU: Not Recently Used, NUR: Not Used Recently)
    - 하드웨어적인 지원을 받아 LRU와 LFU 알고리즘에서 발생한 시간적인 오버헤드를 줄인 방식
    - LRU를 근사시킨 알고리즘이라고 하며, 오랫동안 사용하지 않은 페이지 중 하나를 교체
    - 최근에 참조되지 않은 페이지를 교체 대상으로 선정하는 측면에서 LRU와 비슷하지만 교체되는 페이지의 참조 시점이 가장 오래됐다는 것을 보장하지 못한다
    - 참조 비트(Reference Bit)와 변형 비트(Modified Bit, Dirty Bit)를 사용
        - 참조 비트
            - 페이지가 참조될 때, 1로 자동 세팅, 주기적으로 리셋
            - 페이지가 참조되지 않았을 때는 0이 되며 페이지는 교체
        - 변형 비트
            - 페이지의 내용이 변경되었을 때, 1로 지정
            - 페이지의 내용이 변경되지 않았을 때는 0으로 지정
            - update bit이 1인 페이지를 교체할 때는 wirte back을 해야하는데 이를 최대한 미루자
    - 하드웨어의 자원으로 동작하기 때문에 LRU에 비해 교체 페이지의 선정이 훨씬 빠르게 결정
    - 대부분의 시스템에서 페이지 교체 알고리즘으로 클럭 알고리즘을 채택

### 가상 메모리와 MMU

> CPU는 가상 메모리를 다루고, 실제 해당 주소 접근시 MMU 하드웨어 장치를 통해 물리 메모리로 접근
> 
- 하드웨어 장치를 이용해야 주소 변환이 빠르기 때문에 별도의 장치를 둠

**MMU의 메모리 보호**

- 프로세스는 독립적인 메모리 공간을 가져야 되고, 자신의 공간만 접근해야 한다
- 따라서 한 프로세스에게 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 trap을 발생시키며 보호한다
- base와 limit 레지스터를 활용한 메모리 보호 기법
    - base 레지스터는 메모리상의 프로세스 시작주소를 물리주소로 저장
    - limit 레지스터는 프로세스의 사이즈를 저장
    - 안정성을 위해 해당 레지스터는 커널 모드에서만 수정 가능하도록 설계

## IPC (InterProcess Communication)

- 프로세스는 다른 프로세스의 공간을 접근할 수 없다
    - 프로세스들이 서로의 공간을 쉽게 접근할 수 있다면 프로세스 데이터/코드가 바뀔 수 있으니 위험
- 프로세스간 통신이 필요한 이유
    - 성능을 높이기 위해 여러 프로세스를 만들어 동시에 실행할 경우 이때 프로세스 간 상태 확인 및 데이터 송수신이 필요
1. PIPE(익명 파이프)
    - 두 프로세스간 파이프를 연결해서 통신
    - 한 프로세스는 쓰기만 가능하고 다른 프로세스는 읽기만 가능하다
    - 한쪽 방향으로만 통신 → 반이중 통신
    - 간단하게 사용할 수 있다
2. Named PIPE (FIFO)
    - PIPE는 통신하는 프로세스가 명확할 경우 사용하는 반면, Named PIP는 전혀 모르는 사이의 프로세스들의 통신에 사용
    - 익명 PIPE는 부모가 동일한 프로세스들 사이에서만 통신이 가능하지만 Named PIPE는 부모 프로세스에 관계없이 프로세스들 사이의 통신을 할 수 있다는 점이 특징 → mkfifo함수를 이용해 파일을 생성하기 때문에 가능
    - 익명 PIPE와 동일하게 동시에 읽기/쓰기가 불가능
    - 이는 두 개의 파일을 읽기 전용, 쓰기 전용으로 만들어서 해결할 수 있음
3. 메세지 큐
    - 선입선출 → Named PIPE와 동일
    - 차이점은 Named PIPE가 데이터의 흐름이라면 메세지 큐는 메모리 공간이라는 점??
    - 이는 여러개의 프로세스가 메세지 큐의 데이터에 접근할 수 있음을 의미 ??
4. 공유 메모리
    - 위 세개는 통신을 이용해 데이터를 주고 받는다면, 공유 메모리는 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 지원
    - 프로세스가 공유 메모리 할당을 커널에 요청하면 커널은 해당 프로세스에 메모리 공간을 할당
    - 이후 어떤 프로세스건 해당 메모리 영역에 접근할 수 있다
    - 공유 메모리는 곧바로 메모리에 접근할 수 있기 때문에 IPC 방식 중 속도가 제일 빠르다
5. 메모리 맵
    - 공유 메모리와 메모리를 공유한다는 점은 동일
    - 하지만, 현재 열려져 있는 파일을 공유하는 점에서 차이가 있음
    - 열린 파일이 메모리에 올라가 있으면 다른 프로세스가 해당 파일을 사용할 때 또 다시 파일을 열지 않고 공유한 상태로 사용하는 것이 더 효율적
6. 소켓
    - 소켓을 만들어 통신
    - 소켓 통신은 데이터 교환을 위해 양쪽 PC에서 각각 임의의 포트를 정하고 해당 포트 간의 대화를 통해 데이터를 주고받는 방식. 이 때 각각 PC의 프로세스는 임의의 PORT를 맡아 데이터를 송수신
7. RPC (Remote Procedure Call)
    - 원격 프로시저 호출은 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행 할 수 있게 하는 프로세스간 통신 기술
    - 분산 컴퓨팅 환경에서 많이 사용됐으며, 현재는 MSA에서 마이크로 서비스간에 많이 사용함
    - 서로 다른 환경이지만 서비스간의 프로시저 호출을 가능하게 해줌에 따라 언어에 구애받지 않고 환경에 대한 확장이 가능하며, 좀 더 비즈니스 로직에 집중하여 생산성을 증가시킬 수 있다
    - gRPC (ProtocolBuffer) by Google

## 사용자 스레드 커널 스레드
출처
[https://velog.io/@taehee-kim-dev/사용자-수준-스레드-커널-수준-스레드](https://velog.io/@taehee-kim-dev/%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%A4%80-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%BB%A4%EB%84%90-%EC%88%98%EC%A4%80-%EC%8A%A4%EB%A0%88%EB%93%9C)
[https://m.blog.naver.com/whdgml1996/222076116487](https://m.blog.naver.com/whdgml1996/222076116487)
[https://velog.io/@recordsbeat/스레드-도대체-무엇이길래](https://velog.io/@recordsbeat/%EC%8A%A4%EB%A0%88%EB%93%9C-%EB%8F%84%EB%8C%80%EC%B2%B4-%EB%AC%B4%EC%97%87%EC%9D%B4%EA%B8%B8%EB%9E%98)
[https://medium.com/@unmeshvjoshi/how-java-thread-maps-to-os-thread-e280a9fb2e06](https://medium.com/@unmeshvjoshi/how-java-thread-maps-to-os-thread-e280a9fb2e06)
[https://ahnyezi.github.io/os/OS-4/](https://ahnyezi.github.io/os/OS-4/)

### 사용자 수준 스레드

- 사용자가 스레드 관련 라이브러리로 구현해 사용하는 스레드
- 스레드 관련 모든 행위를 사용자 영역에서 하기 때문에, 커널은 사용자 수준 스레드의 존재를 알지 못하고, 스레드 교환에 개입하지 않는다
- 사용자 수준 스레드 N개가 커널 수준 스레드 1개에 매핑되므로, 다대일 스레드 매핑이라고 한다

**장점**

1. 커널 독립적으로 스케줄링을 할 수 있어 모든 운영체제에 적용 가능, 이식성이 높다
2. 스케줄링이나 동기화를 위해 커널을 호출하지 않으므로, **커널 영역으로 전환하는** 오버헤드가 줄어든다
3. 커널이 아닌 스레드 라이브러리에서 스레드 스케줄링을 제어하므로, 유연한 스케줄링이 가능하다

**단점**

1. 하나의 프로세스로 부터 할당된 여러개의 스레드들 중, 한 스레드가 대기 상태가 되면, 모든 스레드를 실행시킬 수 없게 된다 (커널의 입장에서는 하나의 스레드이므로 여러개 중 하나라도 입출력 등을 하면 '너 I/O 하는 구나? block으로 가있어' 하고 다같이 보내버림)
2. 커널이 스레드 관리에 개입하지 않으므로, 스레드 간 보호에 커널의 보호 방법을 사용할 수 없다. 라이브러리 수준의 보호 방법까지만 사용 가능하다

### 커널 수준 스레드

- 커널이 스레드와 관련된 모든 작업을 관리하는 방식
- 사용자 수준 스레드와 커널 수준 스레드가 1대1로 매핑
- 커널이 직접 스케줄링하고 실행하기 때문에 커널의 관리 지원을 많이 받을 수 있지만, 그 만큼 오버헤드가 늘어난다
- 하지만 커널이 각 스레드들을 개별적으로 관리할 수 있으므로, 동일한 프로세스에서 할당된 여러개의 스레드들 중 한 스레드가 대기상태가 되더라도, 다른 스레드들은 실행시킬 수 있다

### Java Thread는 커널 수준

- Java로 만들어진 프로그램에서는 쓰레드 생성 및 GC에 대한 비용을 줄이기 위해서 Thread Pool을 만드는 방식을 사용
- Java API는 운영체제에 맞는 쓰레드 구현을 추상화 해서 Java에서 쓰레드를 만들어 사용하도록 함
- OS는 C와 C++의 세상이다. OS에게 thread를 할당받기 위해서는 그들의 언어로 이야기 해주어야 한다. JVM은 JNI라는 통역사를 통해 자신에게 thread가 필요하다고 알려준다
- Windows API 이용, 유닉스 계열은 Pthread → OS의 스케줄링 정책을 따름
- 쓰레드의 구현 방식은 OS에 종속적이며 스케줄링 정책 또한 동일

### 디스크 스케줄링 알고리즘

**디스크 물리적 구조**

- platter, track, sector & cylinder, spindle, arm
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/28982bad-1aa2-4778-b2a3-b90411739708/Untitled.png)
    

**디스크 접근 시간**

Seek TIme이 가장 큼. 스케줄링 알고리즘도 헤드의 이동 거리를 줄이는 것이 가장 중요한 목표 

- 탐색 시간(Seek Time)
    - 디스크 헤드를 해당 실린더로 이동하는데 걸리는 시간
- 회전 지연 시간(Rotational Latency Time)
    - 디스크가 회전해서 읽고 쓰려는 섹터가 헤드 위치에 도달하기까지 걸리는 시간
- 전송 시간(Transfer Time)
    - 해당 섹터가 헤드 위치에 도달한 후 데이터를 실제로 섹터에 읽고 쓰는데 소요되는 시간
1. FCFS(First Come First Served)
    - 장점: 기법이 단순하며, 공평하게 요청을 처리
    - 단점: 비효율적
2. SSTF(Shortedst Seek Time First)
    
    현재 헤드에서 가장 가까운 트랙의 요청을 먼저 처리
    
    - 장점: Seek Time이 적다. 즉 트랙을 찾는 시간을 최소화, 처리량(Throughput)을 극대화
    - 단점: 안쪽 및 바깥쪽에 있는 요청들은 기아 현상이 발생할 수도 있다. 응답 시간의 편차가 크다
3. SCAN
    
    헤드셋의 진행방향에 있는 요청을 처리하고, 다시 반대 방향으로 틀어 반대방향에 있는 요청들을 처리
    
    - 장점: SSTF의 바깥쪽 트랙의 기아 가능성을 제거할 수 있고, 응답시간의 편차를 줄일 수 있다
    - 단점: 양 쪽 끝 트랙이 가운데 위치한 트랙보다 대기 시간이 길어짐
4. C-SCAN(Circular Scan)
    
    항상 한쪽 방향에서 반대방향으로 진행하며 트랙의 요청을 처리
    
    SCAN과 다르게 중간에 치고 들어오는 요청이 있어도 요청을 처리하지 않고 큐에 모았다가 일전에 요청한 것들을 다 처리한 후 처리
    
    - 장점: 응답시간의 편차가 매우 적음, SCAN보다 시간 균등성이 좋음
    - 단점: 안쪽이나, 바깥쪽으로 처리할 요청이 없어도 헤드셋이 끝까지 이동하기 때문에 비효율적
5. LOOK, C-LOOk
    
    SCAN과 C-SCAN을 보완. 요청이 진행 방향에서 더이상 없다면, 끝단까지 가지 않고 반대방향으로 가던가(SCAN), 다시 C-SCAN 처음으로
    
    - 장점: 불필요한 헤드 이동시간 제거
    - 단점: 끝단까지 가야할지 말아야 할지 판단하는데 있어서 오버헤드 발생
6. N-STEP SCAN
    - SCAN 기법에 기초. 시작하기 전에 대기하고 있는 요청들을 우선적으로 처리
    - 처리하는 과정 중에 요청이 들어오는 것들은 이후에 모아서, 반대방향으로 진행할 때 서비스
    - 장점: SSTF, SCAN 보다 응답시간의 편차가 적음, 특정 방향에서의 많은 요청으로 인해 반대 방향에 들어온 요청들에 대해 기아현상을 방지할 수 있음

출처
[https://limkydev.tistory.com/165?category=974040](https://limkydev.tistory.com/165?category=974040)
[https://wansook0316.github.io/cs/os/2020/04/06/운영체제-정리-20-디스크-스케줄링-알고리즘.html](https://wansook0316.github.io/cs/os/2020/04/06/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EC%A0%95%EB%A6%AC-20-%EB%94%94%EC%8A%A4%ED%81%AC-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html)
[https://eunhyejung.github.io/os/2018/07/30/operatingsystem-study17.html](https://eunhyejung.github.io/os/2018/07/30/operatingsystem-study17.html)

## 인터럽트
출처
fast campus 운영체제 - 인터럽트 란 / 이준희 강사님
[https://velog.io/@adam2/인터럽트](https://velog.io/@adam2/%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8)

> CPU가 프로그램을 실행하고 있을 때, 입출력 하드웨어 드으이 장치나 또는 예외상황이 발생하여 처리가 필요할 경우에 CPU에 알려서 처리하는 기술
> 

### 인터럽트 필요 이유

- 선점형 스케쥴러 구현 :  프로세스 running 중에 스케쥴러 코드를 실행
    - 타이머 인터럽트 (하드웨어로 부터 일정 시간마다 타이머 인터럽트를 운영체제에 알려줌)
    - 운영체제가 타이머 인터럽트 발생 횟수를 기억해서 5번 타이머 인터럽트가 발생하면, 현재 프로세스를 다른 프로세스로 바꿔준다
- IO Device와의 커뮤니케이션 : 저장매체에서 데이터 처리 완료시, 프로세스를 깨워야 함 (block → ready)
- 예외 상황 핸들링 : 0으로 나누기(Divide-by-Zero Interrupt) 등

### 인터럽드 종류

- 내부 인터럽트
    - Trap이라고 부르며, 주로 프로그램 내부에서 잘못된 명령 또는 잘못된 데이터 사용 시 발생
        - 0 으로 나눴을 때
        - 사용자 모드에서 허용되지 않은 명령 또는 공간 접근 시
        - 계산 결과가 Overflow/Underflow 날 때
- 외부 인터럽트
    - 주로 하드웨어에서 발생
        - 전원 이상
        - 기계 문제
        - 키보드 등 IO관련 이벤트
        - Timer 이벤트
- 소프트웨어 인터럽트 (시스템 콜 인터럽트)
    - 프로그램 처리 중 명령의 요청에 의해 발생한 것 (SVC 인터럽트)
    - 시스템 콜 실행을 위해서는 강제로 코드에 인터럽트 명령을 넣어, CPU에게 실행시켜야 한다
        - 실제 코드
        
        ```c
        mov eax, 1 // 시스템 콜 번호
        mov ebx, 0 // 시스템 콜에 해당하는 인자값
        int 0x80.  // 소프트웨어 인터럽트 명령 (system_call())
        ```
        
        - 인터럽트 명령을 호출하면서 0x80 값을 넘겨줌 → CPU는 사용자 모드를 커널 모드로 바꿔줌 → IDT(Interrupt Descriptor Table)에서 0x80에 해당하는 (주소)함수를 찾아서 실행함 → system_call() 함수에서 eax로 부터 시스템 콜 번호를 찾아서, 해당 번호에 맞는 시스템 콜 함수로 이동 → 함수 실행 후 다시 사용자 모드로 변경

### 인터럽트 발생 처리 과정

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/24e96a65-8fd9-401d-ae91-d06938fa2e3e/Untitled.png)

- 관련 용어
    - 인터럽트 핸들러
        - 실제 인터럽트를 처리하기 위한 루틴으로 인터럽트 서비스 루틴이라고도 한다
        - 운영체제의 코드 영역에는 인터럽트 별로 처리해야 할 내용이 이미 프로그램되어 있다
    - 인터럽트 벡터
        - 인터럽트 발생 시 처리해야 할 인터럽트 핸들러의 주소를 인터럽트 별로 보관하고 있는 테이블
    - PCB
        - 인터럽트 발생 시 수행 중이던 memory 주소, 레지스터 값, 하드웨어 상태 등 저장
