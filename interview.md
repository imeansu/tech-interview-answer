## HTTP의 GET과 POST 비교

- GET

    요청하는 데이터가 HTTP Request Message의 Header부분에 url이 담겨서 전송된다. url에 ? 뒤에 데이터가 붙어서 request가 보내지게 되어 url이라는 한정된 공간에 담겨가기 때문에 전송할 수 있는 데이터의 크기가 제한적이고 그대로 노출되기 때문에 비밀번호 같은 데이터에 대해서는 부적절하다

- POST

    HTTP Request Message의 Body 부분에 데이터가 담겨서 전송된다. 이 때문에 GET 방식보다는 전송할 수 있는 데이터의 크기가 크고 보안면에서 좀 더 낫다 (하지만, 암호화하지 않는 이상 비슷하다)

- GET은 서버에서 데이터를 가져오는 용도, POST는 서버의 값이나 상태를 변경, 추가하기 위해서 사용된다
- GET 방식은 브라우저에서 Caching 할 수 있기 때문에 POST 방식으로 요청해야 할 것을 보내는 데이터가 작고 보안적인 문제가 없다는 이유로 GET방식으로 요청한다면 기존에 Caching되었던 데이터가 응답될 가능성이 존재


## HTTP와 HTTPS

- HTTP 프로토콜
    - 개념
        - HyperText Transfer Protocol
        - 웹 상에서 클라이언트와 서버가 정보를 주고 받을 수 있도록 규약
        - TCP와 UDP를 사용하며, 80번 포트를 사용한다
            - 비연결성: 클라이언트가 요청하고 서버가 응답하면 연결이 끊어진다
            - 무상태(stateless): 요청과 응답이 있고난 이후에 서버는 아무런 상태도 저장하지 않는다
    - 문제점
        - TCP/IP는 도청이 가능하다: 평문이기 때문에 패킷을 수집하는 것만으로도 도청할 수 있다
        - 요청 상대를 확인하지 않기 때문에 위장이 가능하다: 누구인지, 허가된 상대인지, 어디서 보냈는지, 의미 없는 (DoS) 공격인지 확인할 수 없다
        - 완전성을 증명할 수 없다 → 변조가 가능하다: 중간자 공격을 당한다 하더라도 알길이 없다
- HTTPS 프로토콜
    - 개념
        - HyperText Transfer Protocol over Secure Socket Layer
        - 웹 통신 프로토콜인 HTTP에 보안이 강화된 프로토콜
        - 기본 TCP/IP로 443번 포트를 사용한다
        - SSL(Secure Socket Layer) or TLS(Transport Layer Security) 등 다른 프로토콜과 조합하여 암호화 한다


## 프로세스와 스레드

프로세스: 프로그램이 메모리에 올라가 CPU의 할당을 받을 수 있는 것

스레드: 프로세스 안의 여러 실행 단위 흐름

프로세스는 자신만의 고유한 공간과 자원을 할당받아 실행됨

스레드는 같은 프로세스 안 다른 스레드와 공간과 자원을 공유함

프로세스는 각각 별도의 주소공간 할당(독립적)

- Code: 코드 자체를 구성하는 메모리 영역
    - 컴파일된 후 기계어 형태
    - 실행코드(Instruction)
    - CPU는 코드 영역에 저장된 명령어를 하나씩 가져가서 처리
    - 읽기 전용
- Data: 전역변수, 정적변수, 배열 등
    - data: 초기화된 데이터
    - bss: 초기화 되지 않은 데이터
    - 전역 변수와 static 변수 등 저장 (메인 함수가 호출되기 전에 할당)
- Heap: 동적 할당 시 사용
    - new(), malloc() 등
    - 언어 마다 Heap에 저장하는 것이 약간 상이
    - 메소드 호출이 끝나도 사라지지 않고 유지 (GC에 의해서 지워지거나 JVM이 종료될 때까지)
    - 모든 Object 타입
    - 8가지 원시 타입을 제외한 모든 정의된 변수들은 참조 변수이다. 참조 변수는 실행될 때마다 많은 데이터들을 스택 메모리 영역에 뒀다 뺐다 하는게 비효율적이므로, 힙역역에 데이터값이 저장되고 스택메모리에는 간단하게 그 주소만 저장됨
- Stack: 지역변수, 매개변수, 리턴 값 (임시 메모리 영역)
    - heap영역에 생성된 Object 타입의 데이터들에 대한 참조를 위한 값이 할당
    - 8가지 원시 타입에 해당하는 지역변수, 매개변수
    - 메소드 종료되면 메모리가 해제
    - Return Address를 Stack에 저장하고 함수에서 필요한 공간을 할당한 뒤 나중에 다시 지운다
    - EBP 레지스터
        - 현재 stack의 최상단을 가리키는 주소가 들어가 있다
        - 함수가 함수를 부르다가 문제가 생기면 어떤 시점에 어떤 함수를 시행시키다가 문제가 생긴지 알기 어려우므로 존재
    - EAX 레지스터
        - Return 값을 가지고 있음

- 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없으며, 접근을 위해서는 IPC 통신이 필요하다
    - ex) 파이프, 파일, 소켓 등

스레드는 

- 스레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택으로 구성
- 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유
- 스택을 스레드마다 독립적으로 할당하는 이유
    - 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 지역 변수 등을 저장하기 위해 사용되는 메모리 공간
    - 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것

프로세스 제어 블록(Process Control Block, PCB)

- 운영체제의 자료구조
- 운영체제는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 PCB를 생성
- 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU를 반환해야 한느데, 이때 작업의 진행 상황을 모두 PCB에 저장. 그리고 다시 CPU를 할당받게 되면 PCB에 저장되어 있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행
- PCB에 저장되는 정보
    - 프로세스 식별자(Process ID, PID) : 프로세스 식별번호
    - 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장
    - 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소
    - CPU 레지스터 (PC, SP 등)
    - CPU 스케쥴링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
    - 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
    - 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
    - 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정번호 등

Context Switching 

- Cache 초기화
- Memory mapping 초기화
- 커널은 항상 실행되어야 한다

스레드는 Stack만 따로 할당 받고 나머지 영역은 서로 공유

하나의 프로세스가 생성될 때, 기본적으로 하나의 스레드 같이 생성

### 멀티프로세스

> 하나의 응용 프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업을 처리하도록 하는 것

장점: 안전성 (메모리 침범 문제를 OS 차원에서 해결 - 메모리 보호로 이냏 커널을 통해(시스템 콜 )통신이 이루어짐)

단점: 각각 독립된 메모리 영역을 갖고 있어, 작업량 많을 수록 오버헤드 발생. Context Switching으로 인한 성능 저하???

### 멀티스레드

> 하나의 응용 프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 처리하는 것

스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해줌

장점

- 독립적인 프로세스에 비해 공유 메모리만큼의 시간, 자원 손실이 감소
- 전역 변수와 정적 변수에 대한 자료 공유 가능
- 프로세스의 Context Switch와 다르게 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다(프로세스 사이에는 공유하는 메로리가 하나도 없기 때문에 cs가 발생하면 캐쉬에 있는 모든 데이터를 리셋하고 다시 캐쉬 정보를 불러와야 함)

단점: 안전성(하나의 스레드가 데이터 공간을 망가뜨리면, 모든 스레드가 작동 불능 상태)

- 스레드를 많이 생성하면, Context Switching이 많이 일어나 성능 저하
    - 리눅스에서는 Thread를 Process와 같이 다룸
        - 가벼운 스레드, 자식 프로세스와 비슷한 방식으로 생성.
        - 부모 프로세스의 PCB 정보를 포함해 모두 갖지만 PCB 내 대부분의 정보가 포인터로 이루어짐
        - 부모 프로세스의 정보를 포인터로만 갖고 있고 몇몇 구조체에서만 자신이 쓰레드임을 알기 위한 다른 정보가 들어 있음
    - 스레드를 많이 생성하면, 모든 스레드를 스케쥴링해야 하므로, CS가 빈번하게 발생
- 멀티스레드의 안전성은 Critical Section 기법을 통해 대비함 (동기화 작업)

    하나의 스레드가 공유 데이터 값을 변경하는 시점에 다른 스레드가 그 값을 읽으려고 할 때 발생하는 문제를 해결하기 위한 동기화 과정

    상호 배제, 진행, 한정된 대기를 충족해야함

### Thread-safe

- 멀티스레드 환경에서 여러 스레드가 동시에 하나의 객체 및 변수(공유 자원)에 접근할 때, 의도한 대로 동작하는 것을 말한다
- 이러한 상황을 "Thread-safe하다"라고 표현
- Thread-safe 하게 구현하기
    - 이를 위해서는 공유 자원에 접근하는 임계영역(critical section)을 동기화 기법으로 제어해줘야 한다. 이를 '상호배제'라고 한다.
    - 동기화 기법으로는 뮤텍스, 세마포어가 존재
- Reentrant
    - 재진입성이라는 의미로, 어떤 함수가 Reentrant하다는 것은 여러 스레드가 동시에 접근해도 언제나 같은 실행 결과를 보장한다는 의미
    - 이를 만족하기 위해서는 해당 서브루틴에서는 공유자원을 사용하지 않으면 된다
        - 예) 정적 변수를 사용하거나 반환하면 안되고 호출 시 제공된 매개변수만으로 동작해야 한다
    - 따라서, Reentrant하다면 Thread-safe하지만 그 역은 성립하지 않는다

## TCP UDP

TCP(Transmission Control Protocol, 전송제어 프로토콜)

- 대부분 신뢰성과 순차적인 전달을 필요로 한다
- 신뢰성이 없는 인터넷을 통해 종단간에 신뢰성 있는 바이트 스트림을 전송하도록 특별히 설계
- 송신자와 수신자 모두가 소켓이라고 부르는 종단점을 생성
- 연결 설정은 3-way handshake를 통해 이루어짐
- 모든 TCP 연결은
    - 전이중(full-duplex, 전송이 양방향으로 동시에 일어날 수 있음 )
    - 점대점(point to point, 각 연결이 정확히 2개의 종단점을 가지고 있음)

UDP(User Datagram Protocol, 사용자 데이터그램 프로토콜)

## 트랜잭션
https://d2.naver.com/helloworld/407507

- 작업의 완전성을 보장해주는 것
- 논리적인 작업 셋을 모두 완벽하게 처리하거나 또는 처리하지 못할 경우에는 원 상태로 복구해서 작업의 잉ㄹ부분만 적용되는 현상이 발행하지 않게 만들어주는 기능
- 사용자 입장 - 작업의 논리적인 단위, 시스템 입장 - 데이터들을 접근 또는 변경하는 프로그램의 단위

트랜잭션과 Lock

- 잠금은 동시성을 제어하기 위한 기능
- 트랜잭션은 데이터의 정합성을 보장하기 위한 기능
- 여러 커넥션에서 동시에 동일한 자원을 요청할 경우 순서대로 한 시점에는 하나의 커넥션만 변경할 수 있게 해주는 역할

트랜잭션의 특성: ACID 4가지 특성을 만족해야 함

- 원자성(Atomicity): 아무런 문제가 발생되지 않았을 경우에만 모든 작업이 수행되어야 함
- 일관성(Consistency): 데이터베이스에는 오브젝트에 대한 각종 정합성 제약을 추가할 수 있고 데이터 조작 전후에 그 상태를 유지하는 것을 보증하는 것 (트랜잭션은 유효한 상태로만 변경될 수 있음) (ex. 유니크 제약을 설정한 속성이 유지)
- 고립성(Isolation): 일련의 데이터 조작을 복수 사용자가 동시에 실행해도 각각의 처리가 모순 없이 실행되는 것을 보증
- 지속성(Durability): 일련의 데이터 조작을 완료하고 완료 통지를 사용자가 받는 시점에서 그 조작이 영구적이 되어 그 결과를 잃지 않는 것을 나타냅니다

트랜잭션의 상태

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/13305f42-3761-4d96-8f5b-d7e185d84df1/Untitled.png)

- Active: 트랜잭션의 활동 상태. 트랜잭션이 실행 중이며 동작 중인 상태를 말한다
- Failed: 트랜잭션 실패 상태. 트랜잭션이 더이상 정상적으로 진행할 수 없는 상태
- Partially Committed: 트랜잭션의 Commit 명령이 도착한 상태. 트랜잭션의 commit 이전 sql 문이 수행되고 commit만 남은 상태를 말한다
- Committed: 트랜잭션 완료 상태. 트랜잭션이 정상적으로 완료된 상태
- Aborted: 트랜잭션이 취소 상태. 트랜잭션이 취소되고 트랜잭션 실행 이전 데이터로 돌아간 상태

Commit 요청이 들어오면 Partical Commited 상태가 된다. 이후 Commit을 문제없이 수행할 수 있으면 Committed 상태로 전이되고, 만약 오류가 발생하면 Failed 상태가 된다.

## Tree

- 비선형 자료구조
- 계층적 관계를 표현하는 자료구조. 표현에 집중
- 용어
    - 포화 이진 트리: 모든 레벨이 꽉 찬 이진 트리
    - 완전 이진 트리: 위에서 아래, 왼쪽에서 오른쪽으로 순서대로 차곡차곡 채워진 이진 트리
    - 정 이진 트리: 모든 노드가 0개 혹은 2개의 자식 노드만을 갖는 이진 트리
- BST(Binary Search Tree)
    - 규칙
        - 규칙 1: 노드에 저장된 키는 유일하다
        - 규칙 2: 부모의 키가 왼쪽 자식 노드의 키보다 크다
        - 규칙 3: 부모의 키가 오른쪽 자식 노드의 키보다 작다
        - 규칙 4: 왼쪽과 오른쪽 서브트리도 이진 탐색 트리이다
    - 탐색 연산은 O(log n), 편향 트리의 경우 O(n)
- Binary Heap
    - 완전 이진 트리 중 하나
    - 보통 트리는 linkedList로 구현하는 것이 효율적이나 heap은 배열로 많이 구현
    - 삽입: 맨 마지막 노드로 삽입 후 부모 노드와 비교하며 스왑
    - 삭제: 루트 노드를 삭제하고 맨 마지막 노드를 루트노드로 올린다. 양쪽 노드가 모두 작으면 stop,  둘 중 더 큰 노드와 스왑
- Red Black Tree
    - BST를 기반으로 하는 트리 형식의 자료구조
    - Search, Insert, Delete 시간 복잡도: O(log n)
    - 동일한 노드의 개수일 때, depth를 최소화하여 시간 복잡도를 줄이는 것이 핵심 아이디어 (완전 이진 트리의 경우 처럼)
    - Java Collection의 ArrayList도 내부적으로 RBT, HashMap에서의 Separate Chaing에서도 사용
    - 구체적이 내용은 보강 필요!

## 무결성 제약조건

데이터베이스에 저장된 데이터의 무결성을 보장하고 데이터베이스의 상태를 일관되게 유지하는 것

1. 개체 무결성: 기본키는 null 값이나 중복값이 들어갈 수 없다
2. 참조 무결성: 외래키 값은 NULL이거나 참조 릴레이션의 기본키 값과 동일해야 한다
3. 도메인 무결성: 특정 속성의 값이 그 속성이 정의된 도메인에 속한 값이어야 한다
4. 고유 무결성: 특정 속성에 대해 고유한 값을 가지도록 조건이 주어진 경우, 그 속성값은 모두 달라야 한다
5. NULL 무결성: 특정 속성값에 NULL이 올 수 없다는 조건이 주어진 경우, 그 속성값은 NULL 값이 올 수 없다
6. 키 무결성: 한 릴레이션에는 최소한 하나의 키가 존재해야 한다

출처: [https://limkydev.tistory.com/161](https://limkydev.tistory.com/161), [https://kosaf04pyh.tistory.com/202](https://kosaf04pyh.tistory.com/202)

## SOLID 원칙

- SRP(Single Responsibility Principle) 단일 책임 원칙
    - 클래스는 단 하나의 책임을 가져야 하며 클래스를 변경하는 이유는 단 하나이어야 한다
- OCP(Open-Closed Principle): 개방-폐쇄 원칙
    - 확장에는 열려 있어야 하고 변경에는 닫혀 있어야 한다
    - 기존의 코드를 변경하지 않으면서(closed), 기능을 추가할 수 있도록(open) 설계 되어야 한다
- LSP(Liskov Substitution Principle): 리스코프 치환 원칙
    - 상위 타입의 객체를 하위 타입의 객체로 치환해도 상위 타입을 사용하는 프로그램은 정상적으로 동작해야 한다
    - 자식 클래스가 부모 클래스를 대체하기 위해서는 부모의 기능에 대해 오버라이드 하지 않도록 해야 함
    - 즉, 자식 클래스는 부모 클래스의 책임을 무시하거나 재정의하지 않고 확장만 수행하도록 해야 함
- ISP(Interface Segregation Principle): 인터페이스 분리 원칙
    - 인터페이스는 그 인터페이스를 사용하는 클라이언트를 기준으로 분리해야 한다
    - 한 클래스는 자신이 사용하지 않는 인터페이스는 구현하지 말아야 한다. 하나의 일반적인 인터페이스보다 여러개의 구체적인 인터페이스가 낫다
    - SRP는 객체의 단일 책임, ISP는 인터페이스의 단일 책임
- DIP(Dependency Inversion Principle): 의존 역전 원칙
    - 고수준 모듈은 저수준 모듈의 구현에 의존해서는 안된다
    - 의존 관계를 맺을 때 변화하기 쉬운 것 또는 자주 변화하는 것보다는 변화하기 어려운 것, 거의 변화가 없는 것에 의존
    - 구체적인 클래스보다 인터페이스나 추상 클래스와 관계를 맺어야 한다

출처: [https://victorydntmd.tistory.com/291](https://victorydntmd.tistory.com/291)

## 캐시의 지역성

> 속도가 빠른 장치와 느린 장치에서 손도 차이에 따른 병목 현상을 줄이기 위한 메모리
> 

ex1) CPU 코어와 메모리 사이의 병목 현상 환와

ex2) 웹 브라우저 캐시 파일은, 하드디스크와 웹페이지 사이의 병목 현상을 완화

### Caches

- CPU는 2~3개 정도의 캐시 메모리가 사용됨
- 듀얼 코어 프로세서의 캐시 메모리 :  각 코어마다 독립된 L1 캐시 메모리를 가지고, 두 코어가 공유하는 L2 캐시 메모리가 내장됨
- L1, L2, L3 Cache(SRAM)
    - L1 Cache : CPU 내부에 존재, 프로세스와 가장 가까운 캐시, 속도를 위해 I$와 D$로 나뉜다
        - Instruction Cache (I$) : 메모리의 TEXT 영역 데이터를 다루는 캐시
        - Data Cache (D$) : TEXT 영역을 제외한 모든 데이터를 다루는 캐시
    - L2 Cache : CPU와 RAM 사이에 존재, 용량이 큰 캐시, 크기를 위해 L1 캐시 처럼 나누지 않는다
    - L3 Cache : 보통 메인보드에 존재, 멀티 코어 시스템에서 여러 코어가 공유하는 캐시
- 디스크 캐시: 주기억장치(RAM)와 보조기억장치(HDD) 사이에 존재하는 캐시

### 캐시 메모리 작동 원리

- 시간 지역성
    - for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시 후 다시 참조될 가능성이 높음
- 공간 지역성
    - A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시 후 다시 사용될 가능성이 높음
- 캐시에 데이터를 저장할 때는, 참조 지역성(공간)을 최대한 활용하기 위해 해당 데이터 뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다
- CPU가 요청한 데이터가 캐시에 있으면 'Cache Hit', 없어서 DRAM에서 가져오면 'Cache Miss'

### 캐시 미스 3가지 경우

- Cold miss : 해당 메모리 주소를 처음 불러서 나는 미스
- Conflict miss : 캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스 (direct mapped cache에서 많이 발생)
- Capacity miss : 캐시 메모리의 공간이 부족해서 나느 미스 (Conflict는 주소 할당 문제, Capacity는 공간 문제)
- 캐시 크기를 키워서 문제를 해결하려하면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점이 생김

### Cache Metrics

- 캐시의 성능을 측정할 때는 Hit latency와 Miss latency가 중요한 요인으로 꼽힘
- 평균 접근 시간 : Average access tiem = Hit latency  + Miss rate * Miss latency

### 구조와 작동 방식

1. Direct mapped Cache
    - DRAM의 여러 주소가 캐시 메모리의 한 주소에 대응되는 다대일 방식
    - 메모리 주소를 인덱스 필드와 태그 필드로 나누어 인덱스 필드를 캐시 메모리 주소에 맵핑
    - 인덱스 필드 + 태그 필드 + 데이터 필드
    - 단점 : Conflict Miss 발생
2. Fully Associative Cache
    - 비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식
    - 저장할 때는 매우 간단하지만, 찾을 때가 문제
    - 조건이나 규칙이 없어서 특정 캐시 Set 안에 있는 모든 블럭을 한번에 찾아 원하는 데이터가 있는지 검색
    - CAM이라는 특수한 메모리 구조를 사용해야 하지만 가격이 매우 비싸다
3. Set Associative Cache
    - Direct + Fully 방식
    - 특정 행을 지정하고, 그 행안의 어떤 열이든 비어있을 때 저장하는 방식
    - Direct에 비해 검색 속도는 느리지만, 저장이 빠르고 Fully에 비해 저장이 느린 대신 검색이 빠른 중간형
    - 인덱스가 가리키는 공간이 두 개 이상, n-way set associative 캐시라고 부름

### Handling Cache writes

- Write-through
    - 캐시에 데이터가 작성될 때마다 메모리의 데이터를 업데이트
- Write-back
    - 블록이 교체될 때만 메모리의 데이터를 업데이트
    - dirty 비트를 추가하여 교체될 때 dirty 비트가 1이면 메모리의 데이터를 변경

상세 설명: [https://parksb.github.io/article/29.html](https://parksb.github.io/article/29.html)

## 컴파일러

- 초기 컴퓨터 프로그램들은 어셈블리어로 작성
    - 서로 다른 CPU아키텍쳐가 등장할 때마다 매번 똑같은 프로그램 작성(최적화지만 이식성이 떨어짐)
    - 어셈블리어로는 프로그램 작성 속도가 매우 떨어짐(작업 속도)
    - 리눅스의 경우 CPU별로 컨텍스트 스위칭 코드가 존재
- 컴파일러
    - CPU아키텍쳐에 따라서는 컴파일러 프로그램만 만들면 되고, 기존 코드는 수정할 필요가 없다(이식성 증가)
    - 어셈블리어로 작성한 코드보다는 작동 속도가 떨어질 수 있다
- 컴파일 과정
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e6bbde50-f6af-48cc-b34c-73480faa4a87/Untitled.png)
    

출처
[https://openingsound.tistory.com/m/107?category=1171777](https://openingsound.tistory.com/m/107?category=1171777)
[https://st-lab.tistory.com/176](https://st-lab.tistory.com/176)

## 컴파일, 인터프리터, 하이브리드

[https://st-lab.tistory.com/176](https://st-lab.tistory.com/176)

## 메모리 단편화(파편화)

> RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용 가능한 메모리가 충분히 존재하지만 할당이 불가능한 상태
> 

### 단편화의 종류

1. 내부 단편화
    - 메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비
2. 외부 단편화
    - 메모리가 할당되고 해제되는 작업이 반복될 때, 중간 중간 생긴 작은 메모리 공간이 생긴다. 메모리 전체적으로 보았을 때는 충분한 여유공간이 있지만, 프로세스가 필요로하는 메모리양 만큼의 연속된 공간이 없어서 메모리를 할당하지 못하는 상황

### 메모리 단편화 해결방법

1. 페이징(Paging) 기법 (가상 메모리 사용, 외부 단편화 해결, 내부 단편화 존재)
    - 논리(가상)메모리는 페이지(Page)라고 불리는 고정 크기의 블록으로 나뉘어지고, 물리 메모리는 프레임(Frame)이라 불리는 페이지와 같은 크기의 블록들로 나위어짐. 보조 메모리 역시 프레임과 같은 크기의 블록들로 나뉘어짐
    - 할당은 항상 프레임의 정수 배로 할당, 이 때 프로세스가 페이지 경계와 일치하지 않는 크기의 메모리를 요구하게 되면 마지막 페이지 프레임은 전부 사용되지 않고 남아버리는 문제 발생 (내부 단편화)
    - 페이징 기법을 사용하면 연속적이지 않은 공간으로 메모리를 할당할 수 있기 때문에 외부 단편화 해결
    - 페이지 단위를 작게하면 내부 단편화 문제도 해결할 수 있겠지만 대신 page mapping 과정이 많아지므로 오히려 효율이 떨어질 수 있음
2. 세그멘테이션(Segmentation) 기법 (가상 메모리 사용, 내부 단편화 해결, 외부 단편화 존재)
    - 세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈 공간을 찾아서 할당
    - 가상 메모리를 서로 다른 크기의 논리적 단위인 세그먼트로 분할해서 메모리 할당
    - 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 자유 공간들이 많은 수의 작은 조각들로 나뉘어져 못 쓰게 될 수도 있다 (외부 단편화)
3. 메모리 풀(Memory Pool)
    - 필요한 메모리 공간을 필요한 크기, 개수 만큼 사용자가 직접 지정하여 미리 할당받아 놓고 필요할 때마다 사용하고 반납하는 기법
    - 랜덤한 위치에 할당과 해제를 반복하여 단편화를 일으키는 것이 아니라
    - 미리 공간을 할당해놓고 가져다 쓰고 반납하기 때문에 할당과 해제로 인한 외부 단편화가 발행하지 않는다
    - 또한 필요한 크기만틈 할당을 해놓기 때문에 내부 단편화 또한 생기지 않는다
    - 하지만 메모리 단편화로 인한 메모리 낭비량보다 메모리 풀을 만들었지만 쓰지 않았을 때 메모리 양이 커질 경우 사용하지 않아야 한다
    - 메모리 할당, 해제가 잦은 경우에 메모리 풀을 쓰면 효과적
    - 미리 할당해놓고 사용하지 않는 순간에도 계속 할당해놓으므로 메모리 누수가 있는 방식
    
    구현 방법
    
    - 큰 메모리 블록(페이지)을 힙으로 부터 할당
    - 할당 받은 페이지를 각 객체의 크기의 블록으로 나눔
    - 각 객체를 위한 블록을 순차적으로 링크
    - 이 때 현 시점에서 할당할 블록을 특정 포인터가 가리키게 함
    - 메모리 요청이 생기면 현재 헤더 포인터가 가리키는 블록을 돌려준다
    - 할당이 일어난 후 헤더 포인터는 할당 직전에 가리키던 블록이 가리키던 블록을 가리킨다 (링크드 리스트 처럼?)
    - 사용되던 메모리가 해제되어 메모리 풀로 돌아올 경우 헤더 포인터는 그 블록을 가리키고 장금 전까지 헤더 포인터가 기리키던 블록을 돌아온 블록의 당므 포인터가 가리키게 한다

출처: [https://jeong-pro.tistory.com/91](https://jeong-pro.tistory.com/91)

Kernel Memory

- 사용자 모드의 프로세스가 추가적인 메모리를 요구하면 커널 페이지 프레임을 넘겨줌
- 커널 메모리의 특징
    - 사용자 모드 프로세스와 달리 메모리 풀에서 할당하는 정책 사용
    - 커널은 다양한 자료구조를 사용하지만 대충 필요한 메모리의 양이 정해져 있기에 이를 고려하고 적절히 할당됨
    - 일반 프로세스의 페이지는 연속적일 필요가 없으나 커널은 하드웨어와 직접 상호작용하기에 물리적으로 연속적인 페이지 프레임을 할당 받음

Buddy, Slab allocator...

## RESTful

로이 필딩은 HTTP의 주요 저자 중 한 사람으로 그 당시 웹(HTTP)설계의 우수성에 비해 제대로 사용되어지지 못하는 모습에 안타까워하며 웹의 장점을 최대한 활용할 수 있는 아키텍쳐로써 REST를 발표

> URI 는 정보의 자원을 표현해야 한다
자원에 대한 행위는 HTTP Method(GET, POST, PUT, DELETE 등)으로 표현한다
> 

### REST의 특징

1. Uniform Interface : URI로 지정한 리소스에 대한 조작을 통일되고 한정적인 인터페이스로 수행
2. Stateless : API 서버는 들어오는 요청만 단순 처리. 서비스의 자유도가 높아지고 서버에서 불필요한 정보를 관리하지 않음으로써 구현이 단순해짐
3. Cacheable : REST는 HTTP 기존 웹표준 그대로 사용. HTTP 프로토콜 표준에서 사용하는 Last-Modified 태그나 E-Tag를 이용하면 캐싱 구현 가능
4. Self-descriptiveness : REST API 메시지만 보고도 이를 쉽게 이해할 수 있는 자체 표현 구조
5. Client - Server 구조 : REST 서버는 API 제공, 클라이언트는 사용자 인증이나 컨텍스트(세션, 로그인 정보)등을 직접 관리하는 구조로 각각의 역할이 확실히 구눕. 서로 개발해야 할 내용이 명확해지고 의존성 줄어짐
6. 계층형 구조 : REST 서버는 다중 계층으로 구성. 보안, 로드 밸런싱, 암호화 계층을 추가해 구조상의 유연성을 둘 수 있고 PROXY, 게이트웨이 같은 네트워크 기반의 중간매체를 사용할 수 있음???

### REST 단점

- Restriction of HTTP Method: 메소드 형태가 제한 적
- Absence of Standard: 표준의 부재
- RDBMS와 어색한 관계 : RESTful 한 테이블 구조가 필요하게 되는데, 이것보다는 NoSQL쪽이 더 잘 맞는 추세

## Blocking-NonBlocking-Synchronous-Asynchronous
출처
[http://homoefficio.github.io/2017/02/19/Blocking-NonBlocking-Synchronous-Asynchronous/](http://homoefficio.github.io/2017/02/19/Blocking-NonBlocking-Synchronous-Asynchronous/)

### Blocking/NonBlocking

> 호출되는 함수가 바로 리턴하느냐 마느냐가 관심사이다
> 

Blocking

- 호출된 함수가 자신의 작업을 모두 마칠 때까지 호출한 함수에게 제어권을 넘겨주지 않고 대기하게 만든다

NonBlocking

- 호출된 함수가 바로 리턴해서 호출한 함수에게 제어권을 넘겨주고, 호출한 함수가 다른 일을 할 수 있는 기회를 줄 수 있다

### Synchronous/Asynchronous

> 호출되는 함수의 작업 완료 여부를 누가 신경 쓰냐 가 관심사이다
> 

Synchronous

- 호출하는 함수가 호출되는 함수의 작업 완료 후 리턴을 기다리거나, 또는 호출되는 함수로 부터 바로 리턴을 받더라도 작업 완료 여부를 호출하는 함수 스스로 계속 확인하며 신경쓴다

Asynchronous

- 호출되는 함수에게 callback을 전달해서, 호출되는 함수의 작업이 완료되면 호출되는 함수가 전달받은 callback을 실행하고, 호출하는 함수는 작업 완료 여부를 신경쓰지 않는다

### NonBlocking-Sync

- 호출되는 함수는 바로 리턴하고, 호출하는 함수는 작업 완료 여부를 신경쓰는 것
- 신경쓰는 방법이 기다리거나 물어보거나 두 가지가 있는데, NonBlocking 함수를 호출했다면 사실 기다릴 필요는 없고 물어보는 일이 남는다
- NonBlocking 메서드 호출 후 바로 반환 받아서 다른 작업을 할 수 있게 되지만, 메서드 호출에 의해 수행되는 작업이 완료된 것은 아니며, 호출하는 메서드가 호출되는 메서드 쪽에 작업 완료 여부를 계속 문의

### Blocking-Async

- 별로 이점이 없어서 일부러 이 방식을 사용할 필요가 없음 (Blocking-Sync와 성능적 차이가 없지 않나...)
- 의도하지 않게 Blocking-Async로 동작하는 경우가 있다. (원래는 N-A를 추구하다가 의도와는 다르게)
    - 대표적인 케이스 - Node.js와 MySQL 조합
    - Node.js 쪽에서 callback 지옥을 헤치면서 Async로 전진해와도, 결국 DB 작업 호출 시에는 MySQL에서 제공하는 드라이버를 호출하게 되는데, 이 드라이버가 Blocking 방식

### I/O 멀티플렉싱 (I/O Multiplexing)

출처: [https://brunch.co.kr/@myner/41](https://brunch.co.kr/@myner/41)

- 입출력 다중화란 하나의 프로세스 혹은 스레드에서 입력과 출력을 모두 다룰 수 있는 기술
- 각 클라이언트 마다 별도의 프로세스나 스레드를 생성하는 것이 아닌 하나의 스레드에서 다수의 클라이언트에 연결된 소켓(파일 디스크립)을 관리하고 소켓에 이벤트가 발생할 경우에만 별도의 스레드를 만들어 해당 이벤트를 처리하도록 구현
- 입출력 함수는 여전히 블록킹으로 작동하겠지만, 입출력 함수를 호출하기 전에 어떤 파일에서 입출력이 준비가 되었는지 확인할 수 있다
